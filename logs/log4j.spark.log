21/05/03 09:06:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 09:06:36 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 09:06:36 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 09:06:36 INFO SecurityManager: Changing view acls groups to: 
21/05/03 09:06:36 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 09:06:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 09:06:37 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 09:06:37 INFO SparkContext: Running Spark version 3.0.1
21/05/03 09:06:37 INFO ResourceUtils: ==============================================================
21/05/03 09:06:37 INFO ResourceUtils: Resources for spark.driver:

21/05/03 09:06:37 INFO ResourceUtils: ==============================================================
21/05/03 09:06:37 INFO SparkContext: Submitted application: sparklyr
21/05/03 09:06:37 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 09:06:37 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 09:06:37 INFO SecurityManager: Changing view acls groups to: 
21/05/03 09:06:37 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 09:06:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 09:06:37 INFO Utils: Successfully started service 'sparkDriver' on port 50388.
21/05/03 09:06:37 INFO SparkEnv: Registering MapOutputTracker
21/05/03 09:06:37 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 09:06:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 09:06:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 09:06:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 09:06:37 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-03465d10-226f-4acb-aeeb-24f397748061
21/05/03 09:06:37 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 09:06:37 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 09:06:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 09:06:37 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.johnsnowlabs.nlp_spark-nlp_2.11-2.7.3.jar at spark://localhost:50388/jars/com.johnsnowlabs.nlp_spark-nlp_2.11-2.7.3.jar with timestamp 1620047197943
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.typesafe_config-1.3.0.jar at spark://localhost:50388/jars/com.typesafe_config-1.3.0.jar with timestamp 1620047197943
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.rocksdb_rocksdbjni-6.5.3.jar at spark://localhost:50388/jars/org.rocksdb_rocksdbjni-6.5.3.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.2.0.jar at spark://localhost:50388/jars/org.apache.hadoop_hadoop-aws-3.2.0.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.11.603.jar at spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-core-1.11.603.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.11.603.jar at spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-s3-1.11.603.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar at spark://localhost:50388/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.navigamez_greex-1.0.jar at spark://localhost:50388/jars/com.navigamez_greex-1.0.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.json4s_json4s-ext_2.11-3.5.3.jar at spark://localhost:50388/jars/org.json4s_json4s-ext_2.11-3.5.3.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.tensorflow_tensorflow-1.15.0.jar at spark://localhost:50388/jars/org.tensorflow_tensorflow-1.15.0.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/net.sf.trove4j_trove4j-3.0.3.jar at spark://localhost:50388/jars/net.sf.trove4j_trove4j-3.0.3.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://localhost:50388/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.9.jar at spark://localhost:50388/jars/org.apache.httpcomponents_httpclient-4.5.9.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/software.amazon.ion_ion-java-1.0.2.jar at spark://localhost:50388/jars/software.amazon.ion_ion-java-1.0.2.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.6.7.jar at spark://localhost:50388/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.6.7.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.11.jar at spark://localhost:50388/jars/org.apache.httpcomponents_httpcore-4.4.11.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/commons-codec_commons-codec-1.11.jar at spark://localhost:50388/jars/commons-codec_commons-codec-1.11.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.11.603.jar at spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-kms-1.11.603.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.amazonaws_jmespath-java-1.11.603.jar at spark://localhost:50388/jars/com.amazonaws_jmespath-java-1.11.603.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.6.7.2.jar at spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-databind-2.6.7.2.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.6.0.jar at spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-annotations-2.6.0.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.6.7.jar at spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-core-2.6.7.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.google.code.findbugs_annotations-3.0.1.jar at spark://localhost:50388/jars/com.google.code.findbugs_annotations-3.0.1.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar at spark://localhost:50388/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar at spark://localhost:50388/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/it.unimi.dsi_fastutil-7.0.12.jar at spark://localhost:50388/jars/it.unimi.dsi_fastutil-7.0.12.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.projectlombok_lombok-1.16.8.jar at spark://localhost:50388/jars/org.projectlombok_lombok-1.16.8.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.slf4j_slf4j-api-1.7.21.jar at spark://localhost:50388/jars/org.slf4j_slf4j-api-1.7.21.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/net.jcip_jcip-annotations-1.0.jar at spark://localhost:50388/jars/net.jcip_jcip-annotations-1.0.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.1.jar at spark://localhost:50388/jars/com.google.code.findbugs_jsr305-3.0.1.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.google.code.gson_gson-2.3.jar at spark://localhost:50388/jars/com.google.code.gson_gson-2.3.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/dk.brics.automaton_automaton-1.11-8.jar at spark://localhost:50388/jars/dk.brics.automaton_automaton-1.11-8.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/joda-time_joda-time-2.9.5.jar at spark://localhost:50388/jars/joda-time_joda-time-2.9.5.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.joda_joda-convert-1.8.1.jar at spark://localhost:50388/jars/org.joda_joda-convert-1.8.1.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.tensorflow_libtensorflow-1.15.0.jar at spark://localhost:50388/jars/org.tensorflow_libtensorflow-1.15.0.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.tensorflow_libtensorflow_jni-1.15.0.jar at spark://localhost:50388/jars/org.tensorflow_libtensorflow_jni-1.15.0.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:50388/jars/sparklyr-3.0-2.12.jar with timestamp 1620047197947
21/05/03 09:06:38 INFO Executor: Starting executor ID driver on host localhost
21/05/03 09:06:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50389.
21/05/03 09:06:38 INFO NettyBlockTransferService: Server created on localhost:50389
21/05/03 09:06:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 09:06:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 50389, None)
21/05/03 09:06:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50389 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 50389, None)
21/05/03 09:06:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 50389, None)
21/05/03 09:06:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 50389, None)
21/05/03 09:06:38 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 09:06:38 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 09:06:38 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 09:06:41 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 09:06:41 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 09:06:41 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar
21/05/03 09:06:41 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar
21/05/03 09:06:41 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/d08ab5dd-8b0e-4ffd-9ff6-03d383c7e0af
21/05/03 09:06:41 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/d08ab5dd-8b0e-4ffd-9ff6-03d383c7e0af
21/05/03 09:06:41 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/d08ab5dd-8b0e-4ffd-9ff6-03d383c7e0af/_tmp_space.db
21/05/03 09:06:41 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 09:06:42 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 09:06:42 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 09:06:42 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 09:06:42 INFO ObjectStore: ObjectStore, initialize called
21/05/03 09:06:42 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 09:06:42 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 09:06:43 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 09:06:45 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 09:06:45 INFO ObjectStore: Initialized ObjectStore
21/05/03 09:06:45 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 09:06:45 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 09:06:45 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 09:06:45 INFO HiveMetaStore: Added admin role in metastore
21/05/03 09:06:45 INFO HiveMetaStore: Added public role in metastore
21/05/03 09:06:45 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 09:06:45 INFO HiveMetaStore: 0: get_all_functions
21/05/03 09:06:45 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 09:06:45 INFO HiveMetaStore: 0: get_database: default
21/05/03 09:06:45 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 09:06:45 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 09:06:45 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 09:06:45 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 09:06:45 INFO HiveMetaStore: 0: get_database: default
21/05/03 09:06:45 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 09:06:45 INFO HiveMetaStore: 0: get_database: default
21/05/03 09:06:45 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 09:06:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 09:06:45 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 09:06:46 INFO CodeGenerator: Code generated in 203.797166 ms
21/05/03 09:06:46 INFO CodeGenerator: Code generated in 9.803521 ms
21/05/03 09:06:46 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 09:06:46 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 09:06:46 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 09:06:46 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 09:06:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 09:06:46 INFO DAGScheduler: Missing parents: List()
21/05/03 09:06:46 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 09:06:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 09:06:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 09:06:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50389 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 09:06:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 09:06:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 09:06:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 09:06:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 09:06:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:50388 after 17 ms (0 ms spent in bootstraps)
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp1882616161651223413.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/joda-time_joda-time-2.9.5.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/joda-time_joda-time-2.9.5.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2969531499402330465.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/joda-time_joda-time-2.9.5.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.google.code.findbugs_annotations-3.0.1.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.google.code.findbugs_annotations-3.0.1.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp6726217629625771152.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.google.code.findbugs_annotations-3.0.1.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2252479962388585707.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.github.universal-automata_liblevenshtein-3.0.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2739765110114985582.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.rocksdb_rocksdbjni-6.5.3.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.rocksdb_rocksdbjni-6.5.3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2572910338194539639.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.rocksdb_rocksdbjni-6.5.3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.slf4j_slf4j-api-1.7.21.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.slf4j_slf4j-api-1.7.21.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp4369633251269090813.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.slf4j_slf4j-api-1.7.21.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-kms-1.11.603.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-kms-1.11.603.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp975661795982383924.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.amazonaws_aws-java-sdk-kms-1.11.603.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.tensorflow_tensorflow-1.15.0.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.tensorflow_tensorflow-1.15.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp4583285883378926512.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.tensorflow_tensorflow-1.15.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.apache.httpcomponents_httpclient-4.5.9.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.apache.httpcomponents_httpclient-4.5.9.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2021991367106915864.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.apache.httpcomponents_httpclient-4.5.9.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.projectlombok_lombok-1.16.8.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.projectlombok_lombok-1.16.8.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp214229718733925999.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.projectlombok_lombok-1.16.8.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.tensorflow_libtensorflow_jni-1.15.0.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.tensorflow_libtensorflow_jni-1.15.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2485920165942298457.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.tensorflow_libtensorflow_jni-1.15.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.joda_joda-convert-1.8.1.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.joda_joda-convert-1.8.1.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp8423307137010787618.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.joda_joda-convert-1.8.1.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/dk.brics.automaton_automaton-1.11-8.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/dk.brics.automaton_automaton-1.11-8.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2144000852852114303.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/dk.brics.automaton_automaton-1.11-8.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.google.code.findbugs_jsr305-3.0.1.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.google.code.findbugs_jsr305-3.0.1.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp7804441531761881497.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.google.code.findbugs_jsr305-3.0.1.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-databind-2.6.7.2.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-databind-2.6.7.2.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp917132229163556358.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.fasterxml.jackson.core_jackson-databind-2.6.7.2.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/net.jcip_jcip-annotations-1.0.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/net.jcip_jcip-annotations-1.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp5347409623765460972.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/net.jcip_jcip-annotations-1.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.navigamez_greex-1.0.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.navigamez_greex-1.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp1699020969802672551.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.navigamez_greex-1.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.6.7.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.6.7.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2785428183400191443.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.6.7.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/commons-codec_commons-codec-1.11.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/commons-codec_commons-codec-1.11.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp5730563122406025478.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/commons-codec_commons-codec-1.11.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/software.amazon.ion_ion-java-1.0.2.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/software.amazon.ion_ion-java-1.0.2.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp6005795833651995575.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/software.amazon.ion_ion-java-1.0.2.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.johnsnowlabs.nlp_spark-nlp_2.11-2.7.3.jar with timestamp 1620047197943
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.johnsnowlabs.nlp_spark-nlp_2.11-2.7.3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp528542156670365811.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.johnsnowlabs.nlp_spark-nlp_2.11-2.7.3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.tensorflow_libtensorflow-1.15.0.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.tensorflow_libtensorflow-1.15.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp1875219107110672856.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.tensorflow_libtensorflow-1.15.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/commons-logging_commons-logging-1.1.3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp8472967262725500022.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/commons-logging_commons-logging-1.1.3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/net.sf.trove4j_trove4j-3.0.3.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/net.sf.trove4j_trove4j-3.0.3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp8746380158152321343.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/net.sf.trove4j_trove4j-3.0.3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.google.code.gson_gson-2.3.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.google.code.gson_gson-2.3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp264085666451406497.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.google.code.gson_gson-2.3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.json4s_json4s-ext_2.11-3.5.3.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.json4s_json4s-ext_2.11-3.5.3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp4190386425323430879.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.json4s_json4s-ext_2.11-3.5.3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-core-1.11.603.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-core-1.11.603.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp6334795072003331302.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.amazonaws_aws-java-sdk-core-1.11.603.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-core-2.6.7.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-core-2.6.7.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp3526376508460519327.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.fasterxml.jackson.core_jackson-core-2.6.7.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-s3-1.11.603.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-s3-1.11.603.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp8703528853685336766.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.amazonaws_aws-java-sdk-s3-1.11.603.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.typesafe_config-1.3.0.jar with timestamp 1620047197943
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.typesafe_config-1.3.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp1759787764733523998.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.typesafe_config-1.3.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.apache.httpcomponents_httpcore-4.4.11.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.apache.httpcomponents_httpcore-4.4.11.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp5281283819303571817.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.apache.httpcomponents_httpcore-4.4.11.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-annotations-2.6.0.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-annotations-2.6.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp7534845185499184221.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.fasterxml.jackson.core_jackson-annotations-2.6.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.amazonaws_jmespath-java-1.11.603.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.amazonaws_jmespath-java-1.11.603.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp8490591153916052612.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.amazonaws_jmespath-java-1.11.603.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.apache.hadoop_hadoop-aws-3.2.0.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.apache.hadoop_hadoop-aws-3.2.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp4982355453567610522.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.apache.hadoop_hadoop-aws-3.2.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/sparklyr-3.0-2.12.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp8292882551591374761.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/sparklyr-3.0-2.12.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/it.unimi.dsi_fastutil-7.0.12.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/it.unimi.dsi_fastutil-7.0.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp3826999817428922862.tmp
21/05/03 09:06:48 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/it.unimi.dsi_fastutil-7.0.12.jar to class loader
21/05/03 09:06:48 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 09:06:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/05/03 09:06:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2684 bytes result sent to driver
21/05/03 09:06:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 1309 ms on localhost (executor driver) (1/1)
21/05/03 09:06:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 09:06:48 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 1.548 s
21/05/03 09:06:48 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 09:06:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 09:06:48 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 1.589899 s
21/05/03 09:06:48 INFO HiveMetaStore: 0: get_database: default
21/05/03 09:06:48 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 09:06:48 INFO HiveMetaStore: 0: get_database: default
21/05/03 09:06:48 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 09:06:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 09:06:48 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 09:06:48 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 09:06:48 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 09:06:48 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 09:06:48 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 09:06:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 09:06:48 INFO DAGScheduler: Missing parents: List()
21/05/03 09:06:48 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 09:06:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 09:06:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 09:06:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50389 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 09:06:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 09:06:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 09:06:48 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 09:06:48 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 09:06:48 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 09:06:48 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 09:06:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 09:06:48 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 09:06:48 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 10 ms on localhost (executor driver) (1/1)
21/05/03 09:06:48 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 09:06:48 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.017 s
21/05/03 09:06:48 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 09:06:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 09:06:48 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.021461 s
21/05/03 09:36:38 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:50389 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 09:36:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:50389 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 11:06:38 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 11:06:38 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 11:06:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 11:06:38 INFO MemoryStore: MemoryStore cleared
21/05/03 11:06:38 INFO BlockManager: BlockManager stopped
21/05/03 11:06:38 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 11:06:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 11:06:38 INFO SparkContext: Successfully stopped SparkContext
21/05/03 11:06:38 INFO ShutdownHookManager: Shutdown hook called
21/05/03 11:06:38 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-5bd93907-0b26-41b4-9a54-6a43adf7033b
21/05/03 11:06:38 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914
21/05/03 11:42:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 11:42:29 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 11:42:29 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 11:42:29 INFO SecurityManager: Changing view acls groups to: 
21/05/03 11:42:29 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 11:42:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 11:42:29 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 11:42:29 INFO SparkContext: Running Spark version 3.0.1
21/05/03 11:42:29 INFO ResourceUtils: ==============================================================
21/05/03 11:42:29 INFO ResourceUtils: Resources for spark.driver:

21/05/03 11:42:29 INFO ResourceUtils: ==============================================================
21/05/03 11:42:29 INFO SparkContext: Submitted application: sparklyr
21/05/03 11:42:29 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 11:42:29 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 11:42:29 INFO SecurityManager: Changing view acls groups to: 
21/05/03 11:42:29 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 11:42:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 11:42:29 INFO Utils: Successfully started service 'sparkDriver' on port 52500.
21/05/03 11:42:30 INFO SparkEnv: Registering MapOutputTracker
21/05/03 11:42:30 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 11:42:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 11:42:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 11:42:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 11:42:30 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-e989f146-3bb9-4d23-b08f-20be988b8d47
21/05/03 11:42:30 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 11:42:30 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 11:42:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 11:42:30 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 11:42:30 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:52500/jars/sparklyr-3.0-2.12.jar with timestamp 1620056550385
21/05/03 11:42:30 INFO Executor: Starting executor ID driver on host localhost
21/05/03 11:42:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52501.
21/05/03 11:42:30 INFO NettyBlockTransferService: Server created on localhost:52501
21/05/03 11:42:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 11:42:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 52501, None)
21/05/03 11:42:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52501 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 52501, None)
21/05/03 11:42:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 52501, None)
21/05/03 11:42:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 52501, None)
21/05/03 11:42:30 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 11:42:30 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 11:42:30 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 11:42:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 11:42:32 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 11:42:33 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/b66100d7-77bb-40a8-9fcf-5dd67ce71356
21/05/03 11:42:33 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/b66100d7-77bb-40a8-9fcf-5dd67ce71356
21/05/03 11:42:33 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/b66100d7-77bb-40a8-9fcf-5dd67ce71356/_tmp_space.db
21/05/03 11:42:33 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 11:42:33 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 11:42:33 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 11:42:33 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 11:42:33 INFO ObjectStore: ObjectStore, initialize called
21/05/03 11:42:33 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 11:42:33 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 11:42:34 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 11:42:36 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 11:42:36 INFO ObjectStore: Initialized ObjectStore
21/05/03 11:42:36 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 11:42:36 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 11:42:36 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 11:42:36 INFO HiveMetaStore: Added admin role in metastore
21/05/03 11:42:36 INFO HiveMetaStore: Added public role in metastore
21/05/03 11:42:36 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 11:42:36 INFO HiveMetaStore: 0: get_all_functions
21/05/03 11:42:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 11:42:36 INFO HiveMetaStore: 0: get_database: default
21/05/03 11:42:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 11:42:36 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 11:42:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 11:42:36 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 11:42:36 INFO HiveMetaStore: 0: get_database: default
21/05/03 11:42:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 11:42:36 INFO HiveMetaStore: 0: get_database: default
21/05/03 11:42:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 11:42:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 11:42:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 11:42:37 INFO CodeGenerator: Code generated in 166.703455 ms
21/05/03 11:42:37 INFO CodeGenerator: Code generated in 11.553893 ms
21/05/03 11:42:37 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 11:42:37 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 11:42:37 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 11:42:37 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 11:42:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 11:42:37 INFO DAGScheduler: Missing parents: List()
21/05/03 11:42:37 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 11:42:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 11:42:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 11:42:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52501 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 11:42:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 11:42:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 11:42:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 11:42:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 11:42:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 11:42:37 INFO Executor: Fetching spark://localhost:52500/jars/sparklyr-3.0-2.12.jar with timestamp 1620056550385
21/05/03 11:42:37 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:52500 after 14 ms (0 ms spent in bootstraps)
21/05/03 11:42:37 INFO Utils: Fetching spark://localhost:52500/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-2787291e-4b0f-4421-8c18-774a7ccadbb3/userFiles-347cbe8d-1d90-469d-86da-43bb320f17ac/fetchFileTemp7751553932069517878.tmp
21/05/03 11:42:37 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-2787291e-4b0f-4421-8c18-774a7ccadbb3/userFiles-347cbe8d-1d90-469d-86da-43bb320f17ac/sparklyr-3.0-2.12.jar to class loader
21/05/03 11:42:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 11:42:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/05/03 11:42:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2684 bytes result sent to driver
21/05/03 11:42:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 300 ms on localhost (executor driver) (1/1)
21/05/03 11:42:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 11:42:38 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.638 s
21/05/03 11:42:38 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 11:42:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 11:42:38 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.681477 s
21/05/03 12:12:31 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:52501 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 12:38:43 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 12:38:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 12:38:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 12:38:43 INFO MemoryStore: MemoryStore cleared
21/05/03 12:38:43 INFO BlockManager: BlockManager stopped
21/05/03 12:38:43 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 12:38:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 12:38:43 INFO SparkContext: Successfully stopped SparkContext
21/05/03 12:38:43 INFO ShutdownHookManager: Shutdown hook called
21/05/03 12:38:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-49811a8b-b879-4b8a-ad2e-996faa2d33a0
21/05/03 12:38:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-2787291e-4b0f-4421-8c18-774a7ccadbb3
21/05/03 12:39:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 12:39:07 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 12:39:07 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 12:39:07 INFO SecurityManager: Changing view acls groups to: 
21/05/03 12:39:07 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 12:39:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 12:39:08 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 12:39:08 INFO SparkContext: Running Spark version 3.0.1
21/05/03 12:39:08 INFO ResourceUtils: ==============================================================
21/05/03 12:39:08 INFO ResourceUtils: Resources for spark.driver:

21/05/03 12:39:08 INFO ResourceUtils: ==============================================================
21/05/03 12:39:08 INFO SparkContext: Submitted application: sparklyr
21/05/03 12:39:08 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 12:39:08 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 12:39:08 INFO SecurityManager: Changing view acls groups to: 
21/05/03 12:39:08 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 12:39:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 12:39:08 INFO Utils: Successfully started service 'sparkDriver' on port 53432.
21/05/03 12:39:08 INFO SparkEnv: Registering MapOutputTracker
21/05/03 12:39:08 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 12:39:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 12:39:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 12:39:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 12:39:08 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-f3954b5f-6034-4c3b-942c-2ebdab1bd218
21/05/03 12:39:08 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 12:39:08 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 12:39:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 12:39:09 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 12:39:09 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:53432/jars/sparklyr-3.0-2.12.jar with timestamp 1620059949131
21/05/03 12:39:09 INFO Executor: Starting executor ID driver on host localhost
21/05/03 12:39:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53433.
21/05/03 12:39:09 INFO NettyBlockTransferService: Server created on localhost:53433
21/05/03 12:39:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 12:39:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 53433, None)
21/05/03 12:39:09 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53433 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 53433, None)
21/05/03 12:39:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 53433, None)
21/05/03 12:39:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 53433, None)
21/05/03 12:39:09 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 12:39:09 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 12:39:09 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 12:39:11 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 12:39:11 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 12:39:12 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/a6160864-5c50-4161-a447-4185323bfcfa
21/05/03 12:39:12 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/a6160864-5c50-4161-a447-4185323bfcfa
21/05/03 12:39:12 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/a6160864-5c50-4161-a447-4185323bfcfa/_tmp_space.db
21/05/03 12:39:12 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 12:39:12 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 12:39:12 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 12:39:12 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 12:39:12 INFO ObjectStore: ObjectStore, initialize called
21/05/03 12:39:12 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 12:39:12 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 12:39:13 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 12:39:14 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 12:39:14 INFO ObjectStore: Initialized ObjectStore
21/05/03 12:39:14 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 12:39:14 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 12:39:14 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 12:39:15 INFO HiveMetaStore: Added admin role in metastore
21/05/03 12:39:15 INFO HiveMetaStore: Added public role in metastore
21/05/03 12:39:15 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 12:39:15 INFO HiveMetaStore: 0: get_all_functions
21/05/03 12:39:15 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 12:39:15 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:39:15 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:39:15 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 12:39:15 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 12:39:15 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 12:39:15 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:39:15 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:39:15 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:39:15 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:39:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 12:39:15 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 12:39:16 INFO CodeGenerator: Code generated in 180.488651 ms
21/05/03 12:39:16 INFO CodeGenerator: Code generated in 11.448274 ms
21/05/03 12:39:16 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 12:39:16 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 12:39:16 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 12:39:16 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 12:39:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 12:39:16 INFO DAGScheduler: Missing parents: List()
21/05/03 12:39:16 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 12:39:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 12:39:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 12:39:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53433 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 12:39:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 12:39:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 12:39:16 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 12:39:16 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 12:39:16 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 12:39:16 INFO Executor: Fetching spark://localhost:53432/jars/sparklyr-3.0-2.12.jar with timestamp 1620059949131
21/05/03 12:39:16 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:53432 after 15 ms (0 ms spent in bootstraps)
21/05/03 12:39:16 INFO Utils: Fetching spark://localhost:53432/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-7eb9b5f0-4e5a-423a-82e2-f1c0c8b997f8/userFiles-03afcddc-652d-486a-a40d-14af96a2ba6d/fetchFileTemp8923968295953249360.tmp
21/05/03 12:39:16 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-7eb9b5f0-4e5a-423a-82e2-f1c0c8b997f8/userFiles-03afcddc-652d-486a-a40d-14af96a2ba6d/sparklyr-3.0-2.12.jar to class loader
21/05/03 12:39:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 12:39:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 12:39:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2684 bytes result sent to driver
21/05/03 12:39:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 312 ms on localhost (executor driver) (1/1)
21/05/03 12:39:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 12:39:16 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.603 s
21/05/03 12:39:16 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 12:39:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 12:39:16 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.644580 s
21/05/03 12:39:16 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:39:16 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:39:16 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:39:16 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:39:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 12:39:16 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 12:39:17 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 12:39:17 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 12:39:17 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 12:39:17 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 12:39:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 12:39:17 INFO DAGScheduler: Missing parents: List()
21/05/03 12:39:17 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 12:39:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 12:39:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 12:39:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53433 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 12:39:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 12:39:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 12:39:17 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 12:39:17 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 12:39:17 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 12:39:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 12:39:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 12:39:17 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 12:39:17 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 8 ms on localhost (executor driver) (1/1)
21/05/03 12:39:17 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 12:39:17 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.015 s
21/05/03 12:39:17 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 12:39:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 12:39:17 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.017837 s
21/05/03 12:58:13 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 12:58:13 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 12:58:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 12:58:13 INFO MemoryStore: MemoryStore cleared
21/05/03 12:58:13 INFO BlockManager: BlockManager stopped
21/05/03 12:58:13 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 12:58:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 12:58:13 INFO SparkContext: Successfully stopped SparkContext
21/05/03 12:58:13 INFO ShutdownHookManager: Shutdown hook called
21/05/03 12:58:13 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-7eb9b5f0-4e5a-423a-82e2-f1c0c8b997f8
21/05/03 12:58:13 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-403703ff-af93-4288-a25c-524b343926b6
21/05/03 12:59:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 12:59:02 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 12:59:02 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 12:59:02 INFO SecurityManager: Changing view acls groups to: 
21/05/03 12:59:02 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 12:59:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 12:59:03 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 12:59:03 INFO SparkContext: Running Spark version 3.0.1
21/05/03 12:59:03 INFO ResourceUtils: ==============================================================
21/05/03 12:59:03 INFO ResourceUtils: Resources for spark.driver:

21/05/03 12:59:03 INFO ResourceUtils: ==============================================================
21/05/03 12:59:03 INFO SparkContext: Submitted application: sparklyr
21/05/03 12:59:03 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 12:59:03 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 12:59:03 INFO SecurityManager: Changing view acls groups to: 
21/05/03 12:59:03 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 12:59:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 12:59:03 INFO Utils: Successfully started service 'sparkDriver' on port 54001.
21/05/03 12:59:03 INFO SparkEnv: Registering MapOutputTracker
21/05/03 12:59:04 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 12:59:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 12:59:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 12:59:04 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 12:59:04 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-4d05945c-8dc3-4146-9998-e49991ce2446
21/05/03 12:59:04 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 12:59:04 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 12:59:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 12:59:04 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 12:59:04 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:54001/jars/sparklyr-3.0-2.12.jar with timestamp 1620061144350
21/05/03 12:59:04 INFO Executor: Starting executor ID driver on host localhost
21/05/03 12:59:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54002.
21/05/03 12:59:04 INFO NettyBlockTransferService: Server created on localhost:54002
21/05/03 12:59:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 12:59:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 54002, None)
21/05/03 12:59:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54002 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 54002, None)
21/05/03 12:59:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 54002, None)
21/05/03 12:59:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 54002, None)
21/05/03 12:59:04 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 12:59:04 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 12:59:04 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 12:59:06 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 12:59:07 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 12:59:07 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/709cda93-9c37-45d3-a97a-261a2d47e093
21/05/03 12:59:07 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/709cda93-9c37-45d3-a97a-261a2d47e093
21/05/03 12:59:07 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/709cda93-9c37-45d3-a97a-261a2d47e093/_tmp_space.db
21/05/03 12:59:07 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 12:59:07 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 12:59:07 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 12:59:07 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 12:59:07 INFO ObjectStore: ObjectStore, initialize called
21/05/03 12:59:08 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 12:59:08 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 12:59:09 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 12:59:10 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 12:59:10 INFO ObjectStore: Initialized ObjectStore
21/05/03 12:59:10 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 12:59:10 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 12:59:10 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 12:59:10 INFO HiveMetaStore: Added admin role in metastore
21/05/03 12:59:10 INFO HiveMetaStore: Added public role in metastore
21/05/03 12:59:10 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 12:59:10 INFO HiveMetaStore: 0: get_all_functions
21/05/03 12:59:10 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 12:59:10 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:59:10 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:59:10 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 12:59:10 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 12:59:10 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 12:59:10 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:59:10 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:59:10 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:59:10 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:59:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 12:59:10 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 12:59:11 INFO CodeGenerator: Code generated in 174.333682 ms
21/05/03 12:59:11 INFO CodeGenerator: Code generated in 10.74157 ms
21/05/03 12:59:11 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 12:59:11 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 12:59:11 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 12:59:11 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 12:59:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 12:59:11 INFO DAGScheduler: Missing parents: List()
21/05/03 12:59:11 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 12:59:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 12:59:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 12:59:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54002 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 12:59:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 12:59:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 12:59:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 12:59:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 12:59:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 12:59:12 INFO Executor: Fetching spark://localhost:54001/jars/sparklyr-3.0-2.12.jar with timestamp 1620061144350
21/05/03 12:59:12 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:54001 after 14 ms (0 ms spent in bootstraps)
21/05/03 12:59:12 INFO Utils: Fetching spark://localhost:54001/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-10a4c1a3-4937-4df5-a1ee-0e7296a724f9/userFiles-7b342104-0161-44a6-a440-590d72154971/fetchFileTemp6497568111366335735.tmp
21/05/03 12:59:12 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-10a4c1a3-4937-4df5-a1ee-0e7296a724f9/userFiles-7b342104-0161-44a6-a440-590d72154971/sparklyr-3.0-2.12.jar to class loader
21/05/03 12:59:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 12:59:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/05/03 12:59:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 12:59:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 290 ms on localhost (executor driver) (1/1)
21/05/03 12:59:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 12:59:12 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.595 s
21/05/03 12:59:12 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 12:59:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 12:59:12 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.636234 s
21/05/03 12:59:12 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:59:12 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:59:12 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:59:12 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:59:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 12:59:12 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 12:59:12 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:54002 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 12:59:12 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 12:59:12 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 12:59:12 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 12:59:12 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 12:59:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 12:59:12 INFO DAGScheduler: Missing parents: List()
21/05/03 12:59:12 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 12:59:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 12:59:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 12:59:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54002 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 12:59:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 12:59:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 12:59:12 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 12:59:12 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 12:59:12 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 12:59:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 12:59:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 12:59:12 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 12:59:12 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 7 ms on localhost (executor driver) (1/1)
21/05/03 12:59:12 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 12:59:12 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.013 s
21/05/03 12:59:12 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 12:59:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 12:59:12 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.016204 s
21/05/03 13:11:23 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 13:11:23 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 13:11:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 13:11:23 INFO MemoryStore: MemoryStore cleared
21/05/03 13:11:23 INFO BlockManager: BlockManager stopped
21/05/03 13:11:23 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 13:11:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 13:11:23 INFO SparkContext: Successfully stopped SparkContext
21/05/03 13:11:23 INFO ShutdownHookManager: Shutdown hook called
21/05/03 13:11:23 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-10a4c1a3-4937-4df5-a1ee-0e7296a724f9
21/05/03 13:11:23 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-484796dd-181e-48e6-8668-250c55fd10bc
21/05/03 13:12:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 13:12:19 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:12:19 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:12:19 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:12:19 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:12:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:12:19 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:12:20 INFO SparkContext: Running Spark version 3.0.1
21/05/03 13:12:20 INFO ResourceUtils: ==============================================================
21/05/03 13:12:20 INFO ResourceUtils: Resources for spark.driver:

21/05/03 13:12:20 INFO ResourceUtils: ==============================================================
21/05/03 13:12:20 INFO SparkContext: Submitted application: sparklyr
21/05/03 13:12:20 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:12:20 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:12:20 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:12:20 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:12:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:12:20 INFO Utils: Successfully started service 'sparkDriver' on port 54985.
21/05/03 13:12:20 INFO SparkEnv: Registering MapOutputTracker
21/05/03 13:12:20 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 13:12:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 13:12:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 13:12:20 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 13:12:20 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-d74851b2-3e4f-4258-bdcb-04d0c7ba18f3
21/05/03 13:12:20 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 13:12:20 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 13:12:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 13:12:20 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 13:12:20 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:54985/jars/sparklyr-3.0-2.12.jar with timestamp 1620061940577
21/05/03 13:12:20 INFO Executor: Starting executor ID driver on host localhost
21/05/03 13:12:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54986.
21/05/03 13:12:20 INFO NettyBlockTransferService: Server created on localhost:54986
21/05/03 13:12:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 13:12:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 54986, None)
21/05/03 13:12:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54986 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 54986, None)
21/05/03 13:12:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 54986, None)
21/05/03 13:12:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 54986, None)
21/05/03 13:12:20 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:12:20 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 13:12:20 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 13:12:23 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 13:12:23 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:12:23 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/cebfcc1f-da3c-4625-acb1-382145cefe5b
21/05/03 13:12:23 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/cebfcc1f-da3c-4625-acb1-382145cefe5b
21/05/03 13:12:23 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/cebfcc1f-da3c-4625-acb1-382145cefe5b/_tmp_space.db
21/05/03 13:12:23 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 13:12:24 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 13:12:24 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 13:12:24 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 13:12:24 INFO ObjectStore: ObjectStore, initialize called
21/05/03 13:12:24 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 13:12:24 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 13:12:25 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 13:12:26 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 13:12:26 INFO ObjectStore: Initialized ObjectStore
21/05/03 13:12:26 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 13:12:26 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 13:12:26 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 13:12:26 INFO HiveMetaStore: Added admin role in metastore
21/05/03 13:12:26 INFO HiveMetaStore: Added public role in metastore
21/05/03 13:12:26 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 13:12:26 INFO HiveMetaStore: 0: get_all_functions
21/05/03 13:12:26 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 13:12:26 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:12:26 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:12:26 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 13:12:26 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 13:12:26 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 13:12:26 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:12:26 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:12:26 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:12:26 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:12:26 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:12:26 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:12:27 INFO CodeGenerator: Code generated in 166.902837 ms
21/05/03 13:12:27 INFO CodeGenerator: Code generated in 10.357411 ms
21/05/03 13:12:27 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:12:27 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 13:12:27 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 13:12:27 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 13:12:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 13:12:27 INFO DAGScheduler: Missing parents: List()
21/05/03 13:12:27 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 13:12:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:12:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:12:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54986 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:12:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 13:12:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:12:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 13:12:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:12:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 13:12:28 INFO Executor: Fetching spark://localhost:54985/jars/sparklyr-3.0-2.12.jar with timestamp 1620061940577
21/05/03 13:12:28 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:54985 after 14 ms (0 ms spent in bootstraps)
21/05/03 13:12:28 INFO Utils: Fetching spark://localhost:54985/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-12f1f9a9-2fb3-4ad5-8a27-0001e4152f2d/userFiles-459f09b8-d65d-4b72-85bb-52b4096fe162/fetchFileTemp5165540833136966390.tmp
21/05/03 13:12:28 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-12f1f9a9-2fb3-4ad5-8a27-0001e4152f2d/userFiles-459f09b8-d65d-4b72-85bb-52b4096fe162/sparklyr-3.0-2.12.jar to class loader
21/05/03 13:12:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 13:12:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 13:12:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 285 ms on localhost (executor driver) (1/1)
21/05/03 13:12:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 13:12:28 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.527 s
21/05/03 13:12:28 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:12:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 13:12:28 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.564598 s
21/05/03 13:12:28 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:12:28 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:12:28 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:12:28 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:12:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:12:28 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:12:28 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:12:28 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 13:12:28 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 13:12:28 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 13:12:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 13:12:28 INFO DAGScheduler: Missing parents: List()
21/05/03 13:12:28 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 13:12:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:12:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:12:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54986 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:12:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 13:12:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:12:28 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 13:12:28 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:12:28 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 13:12:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 13:12:28 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 13:12:28 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 6 ms on localhost (executor driver) (1/1)
21/05/03 13:12:28 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 13:12:28 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.031 s
21/05/03 13:12:28 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:12:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 13:12:28 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.035436 s
21/05/03 13:12:28 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:54986 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:31:40 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 13:31:40 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 13:31:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 13:31:40 INFO MemoryStore: MemoryStore cleared
21/05/03 13:31:40 INFO BlockManager: BlockManager stopped
21/05/03 13:31:40 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 13:31:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 13:31:40 INFO SparkContext: Successfully stopped SparkContext
21/05/03 13:31:40 INFO ShutdownHookManager: Shutdown hook called
21/05/03 13:31:40 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a98ca65c-70f6-4732-b320-f03d57106d6b
21/05/03 13:31:40 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-12f1f9a9-2fb3-4ad5-8a27-0001e4152f2d
21/05/03 13:33:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 13:33:53 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:33:53 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:33:53 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:33:53 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:33:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:33:54 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:33:54 INFO SparkContext: Running Spark version 3.0.1
21/05/03 13:33:54 INFO ResourceUtils: ==============================================================
21/05/03 13:33:54 INFO ResourceUtils: Resources for spark.driver:

21/05/03 13:33:54 INFO ResourceUtils: ==============================================================
21/05/03 13:33:54 INFO SparkContext: Submitted application: sparklyr
21/05/03 13:33:54 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:33:54 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:33:54 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:33:54 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:33:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:33:54 INFO Utils: Successfully started service 'sparkDriver' on port 55475.
21/05/03 13:33:54 INFO SparkEnv: Registering MapOutputTracker
21/05/03 13:33:54 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 13:33:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 13:33:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 13:33:54 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 13:33:54 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-8649120c-9ccd-4325-96df-24873202b04b
21/05/03 13:33:54 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 13:33:54 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 13:33:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 13:33:55 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 13:33:55 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:55475/jars/sparklyr-3.0-2.12.jar with timestamp 1620063235149
21/05/03 13:33:55 INFO Executor: Starting executor ID driver on host localhost
21/05/03 13:33:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55477.
21/05/03 13:33:55 INFO NettyBlockTransferService: Server created on localhost:55477
21/05/03 13:33:55 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 13:33:55 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 55477, None)
21/05/03 13:33:55 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55477 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 55477, None)
21/05/03 13:33:55 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 55477, None)
21/05/03 13:33:55 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 55477, None)
21/05/03 13:33:55 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:33:55 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 13:33:55 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 13:33:57 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 13:33:57 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:33:58 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/505d33ea-c8e2-40bc-b48c-b790312f665f
21/05/03 13:33:58 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/505d33ea-c8e2-40bc-b48c-b790312f665f
21/05/03 13:33:58 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/505d33ea-c8e2-40bc-b48c-b790312f665f/_tmp_space.db
21/05/03 13:33:58 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 13:33:58 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 13:33:58 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 13:33:58 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 13:33:58 INFO ObjectStore: ObjectStore, initialize called
21/05/03 13:33:58 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 13:33:58 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 13:33:59 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 13:34:00 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 13:34:00 INFO ObjectStore: Initialized ObjectStore
21/05/03 13:34:00 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 13:34:00 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 13:34:00 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 13:34:01 INFO HiveMetaStore: Added admin role in metastore
21/05/03 13:34:01 INFO HiveMetaStore: Added public role in metastore
21/05/03 13:34:01 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 13:34:01 INFO HiveMetaStore: 0: get_all_functions
21/05/03 13:34:01 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 13:34:01 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:34:01 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:34:01 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 13:34:01 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 13:34:01 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 13:34:01 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:34:01 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:34:01 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:34:01 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:34:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:34:01 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:34:02 INFO CodeGenerator: Code generated in 163.812027 ms
21/05/03 13:34:02 INFO CodeGenerator: Code generated in 9.934509 ms
21/05/03 13:34:02 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:34:02 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 13:34:02 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 13:34:02 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 13:34:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 13:34:02 INFO DAGScheduler: Missing parents: List()
21/05/03 13:34:02 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 13:34:02 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:34:02 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:34:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55477 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:34:02 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 13:34:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:34:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 13:34:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:34:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 13:34:02 INFO Executor: Fetching spark://localhost:55475/jars/sparklyr-3.0-2.12.jar with timestamp 1620063235149
21/05/03 13:34:02 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:55475 after 14 ms (0 ms spent in bootstraps)
21/05/03 13:34:02 INFO Utils: Fetching spark://localhost:55475/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-60b843c2-1b3a-4b6f-9ce9-15cfa19ebd63/userFiles-4076e07e-331d-41c1-86a2-cc543f0744f4/fetchFileTemp4211403954103139419.tmp
21/05/03 13:34:02 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-60b843c2-1b3a-4b6f-9ce9-15cfa19ebd63/userFiles-4076e07e-331d-41c1-86a2-cc543f0744f4/sparklyr-3.0-2.12.jar to class loader
21/05/03 13:34:02 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:34:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 13:34:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 13:34:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 276 ms on localhost (executor driver) (1/1)
21/05/03 13:34:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 13:34:02 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.551 s
21/05/03 13:34:02 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:34:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 13:34:02 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.587938 s
21/05/03 13:34:02 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:34:02 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:34:02 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:34:02 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:34:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:34:02 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:34:02 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:34:02 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 13:34:02 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 13:34:02 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 13:34:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 13:34:02 INFO DAGScheduler: Missing parents: List()
21/05/03 13:34:02 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 13:34:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:34:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:34:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55477 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:34:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 13:34:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:34:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 13:34:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:34:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 13:34:02 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:34:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 13:34:02 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 13:34:02 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 6 ms on localhost (executor driver) (1/1)
21/05/03 13:34:02 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 13:34:02 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.013 s
21/05/03 13:34:02 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:34:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 13:34:02 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.016480 s
21/05/03 13:35:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:55477 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:35:55 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:55477 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:42:38 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 13:42:38 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 13:42:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 13:42:38 INFO MemoryStore: MemoryStore cleared
21/05/03 13:42:38 INFO BlockManager: BlockManager stopped
21/05/03 13:42:38 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 13:42:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 13:42:38 INFO SparkContext: Successfully stopped SparkContext
21/05/03 13:42:38 INFO ShutdownHookManager: Shutdown hook called
21/05/03 13:42:38 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-04e78920-7d83-4b5e-b889-28060dfb8a86
21/05/03 13:42:38 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-60b843c2-1b3a-4b6f-9ce9-15cfa19ebd63
21/05/03 13:43:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 13:43:28 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:43:28 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:43:28 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:43:28 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:43:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:43:29 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:43:29 INFO SparkContext: Running Spark version 3.0.1
21/05/03 13:43:29 INFO ResourceUtils: ==============================================================
21/05/03 13:43:29 INFO ResourceUtils: Resources for spark.driver:

21/05/03 13:43:29 INFO ResourceUtils: ==============================================================
21/05/03 13:43:29 INFO SparkContext: Submitted application: sparklyr
21/05/03 13:43:29 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:43:29 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:43:29 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:43:29 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:43:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:43:29 INFO Utils: Successfully started service 'sparkDriver' on port 55886.
21/05/03 13:43:29 INFO SparkEnv: Registering MapOutputTracker
21/05/03 13:43:29 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 13:43:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 13:43:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 13:43:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 13:43:30 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-352a5ad7-e36c-4a3e-9ff6-05b486bf5a7e
21/05/03 13:43:30 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 13:43:30 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 13:43:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 13:43:30 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 13:43:30 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:55886/jars/sparklyr-3.0-2.12.jar with timestamp 1620063810310
21/05/03 13:43:30 INFO Executor: Starting executor ID driver on host localhost
21/05/03 13:43:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55887.
21/05/03 13:43:30 INFO NettyBlockTransferService: Server created on localhost:55887
21/05/03 13:43:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 13:43:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 55887, None)
21/05/03 13:43:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55887 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 55887, None)
21/05/03 13:43:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 55887, None)
21/05/03 13:43:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 55887, None)
21/05/03 13:43:30 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:43:30 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 13:43:30 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 13:43:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 13:43:32 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:43:33 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/23eb9f4f-6720-47fb-ac91-bd6cd146dccc
21/05/03 13:43:33 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/23eb9f4f-6720-47fb-ac91-bd6cd146dccc
21/05/03 13:43:33 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/23eb9f4f-6720-47fb-ac91-bd6cd146dccc/_tmp_space.db
21/05/03 13:43:33 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 13:43:33 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 13:43:33 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 13:43:33 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 13:43:33 INFO ObjectStore: ObjectStore, initialize called
21/05/03 13:43:33 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 13:43:33 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 13:43:34 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 13:43:35 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 13:43:35 INFO ObjectStore: Initialized ObjectStore
21/05/03 13:43:35 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 13:43:35 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 13:43:35 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 13:43:36 INFO HiveMetaStore: Added admin role in metastore
21/05/03 13:43:36 INFO HiveMetaStore: Added public role in metastore
21/05/03 13:43:36 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 13:43:36 INFO HiveMetaStore: 0: get_all_functions
21/05/03 13:43:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 13:43:36 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:43:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:43:36 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 13:43:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 13:43:36 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 13:43:36 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:43:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:43:36 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:43:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:43:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:43:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:43:37 INFO CodeGenerator: Code generated in 162.633674 ms
21/05/03 13:43:37 INFO CodeGenerator: Code generated in 10.234067 ms
21/05/03 13:43:37 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:43:37 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 13:43:37 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 13:43:37 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 13:43:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 13:43:37 INFO DAGScheduler: Missing parents: List()
21/05/03 13:43:37 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 13:43:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:43:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:43:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55887 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:43:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 13:43:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:43:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 13:43:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:43:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 13:43:37 INFO Executor: Fetching spark://localhost:55886/jars/sparklyr-3.0-2.12.jar with timestamp 1620063810310
21/05/03 13:43:37 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:55886 after 15 ms (0 ms spent in bootstraps)
21/05/03 13:43:37 INFO Utils: Fetching spark://localhost:55886/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-213e08ad-d562-4267-8b73-2e7712aa9b15/userFiles-79fb2bb8-a8fa-41bb-b049-6d6bc27bdd8a/fetchFileTemp107034832506048465.tmp
21/05/03 13:43:37 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-213e08ad-d562-4267-8b73-2e7712aa9b15/userFiles-79fb2bb8-a8fa-41bb-b049-6d6bc27bdd8a/sparklyr-3.0-2.12.jar to class loader
21/05/03 13:43:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:43:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 13:43:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 13:43:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 275 ms on localhost (executor driver) (1/1)
21/05/03 13:43:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 13:43:37 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.539 s
21/05/03 13:43:37 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:43:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 13:43:37 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.585511 s
21/05/03 13:43:37 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:43:37 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:43:37 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:43:37 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:43:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:43:37 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:43:37 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:55887 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:43:37 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:43:37 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 13:43:37 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 13:43:37 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 13:43:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 13:43:37 INFO DAGScheduler: Missing parents: List()
21/05/03 13:43:37 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 13:43:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:43:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:43:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55887 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:43:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 13:43:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:43:37 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 13:43:37 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:43:37 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 13:43:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:43:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 13:43:37 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 13:43:37 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 7 ms on localhost (executor driver) (1/1)
21/05/03 13:43:37 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 13:43:37 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.013 s
21/05/03 13:43:37 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:43:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 13:43:37 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.016170 s
