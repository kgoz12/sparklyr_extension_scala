21/05/03 09:06:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 09:06:36 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 09:06:36 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 09:06:36 INFO SecurityManager: Changing view acls groups to: 
21/05/03 09:06:36 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 09:06:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 09:06:37 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 09:06:37 INFO SparkContext: Running Spark version 3.0.1
21/05/03 09:06:37 INFO ResourceUtils: ==============================================================
21/05/03 09:06:37 INFO ResourceUtils: Resources for spark.driver:

21/05/03 09:06:37 INFO ResourceUtils: ==============================================================
21/05/03 09:06:37 INFO SparkContext: Submitted application: sparklyr
21/05/03 09:06:37 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 09:06:37 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 09:06:37 INFO SecurityManager: Changing view acls groups to: 
21/05/03 09:06:37 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 09:06:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 09:06:37 INFO Utils: Successfully started service 'sparkDriver' on port 50388.
21/05/03 09:06:37 INFO SparkEnv: Registering MapOutputTracker
21/05/03 09:06:37 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 09:06:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 09:06:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 09:06:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 09:06:37 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-03465d10-226f-4acb-aeeb-24f397748061
21/05/03 09:06:37 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 09:06:37 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 09:06:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 09:06:37 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.johnsnowlabs.nlp_spark-nlp_2.11-2.7.3.jar at spark://localhost:50388/jars/com.johnsnowlabs.nlp_spark-nlp_2.11-2.7.3.jar with timestamp 1620047197943
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.typesafe_config-1.3.0.jar at spark://localhost:50388/jars/com.typesafe_config-1.3.0.jar with timestamp 1620047197943
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.rocksdb_rocksdbjni-6.5.3.jar at spark://localhost:50388/jars/org.rocksdb_rocksdbjni-6.5.3.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.2.0.jar at spark://localhost:50388/jars/org.apache.hadoop_hadoop-aws-3.2.0.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.11.603.jar at spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-core-1.11.603.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.11.603.jar at spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-s3-1.11.603.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar at spark://localhost:50388/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.navigamez_greex-1.0.jar at spark://localhost:50388/jars/com.navigamez_greex-1.0.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.json4s_json4s-ext_2.11-3.5.3.jar at spark://localhost:50388/jars/org.json4s_json4s-ext_2.11-3.5.3.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.tensorflow_tensorflow-1.15.0.jar at spark://localhost:50388/jars/org.tensorflow_tensorflow-1.15.0.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/net.sf.trove4j_trove4j-3.0.3.jar at spark://localhost:50388/jars/net.sf.trove4j_trove4j-3.0.3.jar with timestamp 1620047197944
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://localhost:50388/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.9.jar at spark://localhost:50388/jars/org.apache.httpcomponents_httpclient-4.5.9.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/software.amazon.ion_ion-java-1.0.2.jar at spark://localhost:50388/jars/software.amazon.ion_ion-java-1.0.2.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.6.7.jar at spark://localhost:50388/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.6.7.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.11.jar at spark://localhost:50388/jars/org.apache.httpcomponents_httpcore-4.4.11.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/commons-codec_commons-codec-1.11.jar at spark://localhost:50388/jars/commons-codec_commons-codec-1.11.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.11.603.jar at spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-kms-1.11.603.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.amazonaws_jmespath-java-1.11.603.jar at spark://localhost:50388/jars/com.amazonaws_jmespath-java-1.11.603.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.6.7.2.jar at spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-databind-2.6.7.2.jar with timestamp 1620047197945
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.6.0.jar at spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-annotations-2.6.0.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.6.7.jar at spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-core-2.6.7.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.google.code.findbugs_annotations-3.0.1.jar at spark://localhost:50388/jars/com.google.code.findbugs_annotations-3.0.1.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar at spark://localhost:50388/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar at spark://localhost:50388/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/it.unimi.dsi_fastutil-7.0.12.jar at spark://localhost:50388/jars/it.unimi.dsi_fastutil-7.0.12.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.projectlombok_lombok-1.16.8.jar at spark://localhost:50388/jars/org.projectlombok_lombok-1.16.8.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.slf4j_slf4j-api-1.7.21.jar at spark://localhost:50388/jars/org.slf4j_slf4j-api-1.7.21.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/net.jcip_jcip-annotations-1.0.jar at spark://localhost:50388/jars/net.jcip_jcip-annotations-1.0.jar with timestamp 1620047197946
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.1.jar at spark://localhost:50388/jars/com.google.code.findbugs_jsr305-3.0.1.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/com.google.code.gson_gson-2.3.jar at spark://localhost:50388/jars/com.google.code.gson_gson-2.3.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/dk.brics.automaton_automaton-1.11-8.jar at spark://localhost:50388/jars/dk.brics.automaton_automaton-1.11-8.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/joda-time_joda-time-2.9.5.jar at spark://localhost:50388/jars/joda-time_joda-time-2.9.5.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.joda_joda-convert-1.8.1.jar at spark://localhost:50388/jars/org.joda_joda-convert-1.8.1.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.tensorflow_libtensorflow-1.15.0.jar at spark://localhost:50388/jars/org.tensorflow_libtensorflow-1.15.0.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/.ivy2/jars/org.tensorflow_libtensorflow_jni-1.15.0.jar at spark://localhost:50388/jars/org.tensorflow_libtensorflow_jni-1.15.0.jar with timestamp 1620047197947
21/05/03 09:06:37 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:50388/jars/sparklyr-3.0-2.12.jar with timestamp 1620047197947
21/05/03 09:06:38 INFO Executor: Starting executor ID driver on host localhost
21/05/03 09:06:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50389.
21/05/03 09:06:38 INFO NettyBlockTransferService: Server created on localhost:50389
21/05/03 09:06:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 09:06:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 50389, None)
21/05/03 09:06:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50389 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 50389, None)
21/05/03 09:06:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 50389, None)
21/05/03 09:06:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 50389, None)
21/05/03 09:06:38 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 09:06:38 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 09:06:38 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 09:06:41 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 09:06:41 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 09:06:41 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar
21/05/03 09:06:41 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar
21/05/03 09:06:41 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/d08ab5dd-8b0e-4ffd-9ff6-03d383c7e0af
21/05/03 09:06:41 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/d08ab5dd-8b0e-4ffd-9ff6-03d383c7e0af
21/05/03 09:06:41 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/d08ab5dd-8b0e-4ffd-9ff6-03d383c7e0af/_tmp_space.db
21/05/03 09:06:41 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 09:06:42 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 09:06:42 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 09:06:42 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 09:06:42 INFO ObjectStore: ObjectStore, initialize called
21/05/03 09:06:42 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 09:06:42 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 09:06:43 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 09:06:45 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 09:06:45 INFO ObjectStore: Initialized ObjectStore
21/05/03 09:06:45 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 09:06:45 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 09:06:45 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 09:06:45 INFO HiveMetaStore: Added admin role in metastore
21/05/03 09:06:45 INFO HiveMetaStore: Added public role in metastore
21/05/03 09:06:45 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 09:06:45 INFO HiveMetaStore: 0: get_all_functions
21/05/03 09:06:45 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 09:06:45 INFO HiveMetaStore: 0: get_database: default
21/05/03 09:06:45 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 09:06:45 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 09:06:45 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 09:06:45 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 09:06:45 INFO HiveMetaStore: 0: get_database: default
21/05/03 09:06:45 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 09:06:45 INFO HiveMetaStore: 0: get_database: default
21/05/03 09:06:45 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 09:06:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 09:06:45 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 09:06:46 INFO CodeGenerator: Code generated in 203.797166 ms
21/05/03 09:06:46 INFO CodeGenerator: Code generated in 9.803521 ms
21/05/03 09:06:46 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 09:06:46 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 09:06:46 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 09:06:46 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 09:06:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 09:06:46 INFO DAGScheduler: Missing parents: List()
21/05/03 09:06:46 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 09:06:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 09:06:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 09:06:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:50389 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 09:06:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 09:06:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 09:06:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 09:06:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 09:06:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:50388 after 17 ms (0 ms spent in bootstraps)
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp1882616161651223413.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/joda-time_joda-time-2.9.5.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/joda-time_joda-time-2.9.5.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2969531499402330465.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/joda-time_joda-time-2.9.5.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.google.code.findbugs_annotations-3.0.1.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.google.code.findbugs_annotations-3.0.1.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp6726217629625771152.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.google.code.findbugs_annotations-3.0.1.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2252479962388585707.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.github.universal-automata_liblevenshtein-3.0.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2739765110114985582.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.rocksdb_rocksdbjni-6.5.3.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.rocksdb_rocksdbjni-6.5.3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2572910338194539639.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.rocksdb_rocksdbjni-6.5.3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.slf4j_slf4j-api-1.7.21.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.slf4j_slf4j-api-1.7.21.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp4369633251269090813.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.slf4j_slf4j-api-1.7.21.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-kms-1.11.603.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-kms-1.11.603.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp975661795982383924.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.amazonaws_aws-java-sdk-kms-1.11.603.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.tensorflow_tensorflow-1.15.0.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.tensorflow_tensorflow-1.15.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp4583285883378926512.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.tensorflow_tensorflow-1.15.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.apache.httpcomponents_httpclient-4.5.9.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.apache.httpcomponents_httpclient-4.5.9.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2021991367106915864.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.apache.httpcomponents_httpclient-4.5.9.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.projectlombok_lombok-1.16.8.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.projectlombok_lombok-1.16.8.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp214229718733925999.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.projectlombok_lombok-1.16.8.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.tensorflow_libtensorflow_jni-1.15.0.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.tensorflow_libtensorflow_jni-1.15.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2485920165942298457.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.tensorflow_libtensorflow_jni-1.15.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.joda_joda-convert-1.8.1.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.joda_joda-convert-1.8.1.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp8423307137010787618.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.joda_joda-convert-1.8.1.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/dk.brics.automaton_automaton-1.11-8.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/dk.brics.automaton_automaton-1.11-8.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2144000852852114303.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/dk.brics.automaton_automaton-1.11-8.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.google.code.findbugs_jsr305-3.0.1.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.google.code.findbugs_jsr305-3.0.1.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp7804441531761881497.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.google.code.findbugs_jsr305-3.0.1.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-databind-2.6.7.2.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-databind-2.6.7.2.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp917132229163556358.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.fasterxml.jackson.core_jackson-databind-2.6.7.2.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/net.jcip_jcip-annotations-1.0.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/net.jcip_jcip-annotations-1.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp5347409623765460972.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/net.jcip_jcip-annotations-1.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.navigamez_greex-1.0.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.navigamez_greex-1.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp1699020969802672551.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.navigamez_greex-1.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.6.7.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.6.7.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp2785428183400191443.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.6.7.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/commons-codec_commons-codec-1.11.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/commons-codec_commons-codec-1.11.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp5730563122406025478.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/commons-codec_commons-codec-1.11.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/software.amazon.ion_ion-java-1.0.2.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/software.amazon.ion_ion-java-1.0.2.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp6005795833651995575.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/software.amazon.ion_ion-java-1.0.2.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.johnsnowlabs.nlp_spark-nlp_2.11-2.7.3.jar with timestamp 1620047197943
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.johnsnowlabs.nlp_spark-nlp_2.11-2.7.3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp528542156670365811.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.johnsnowlabs.nlp_spark-nlp_2.11-2.7.3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.tensorflow_libtensorflow-1.15.0.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.tensorflow_libtensorflow-1.15.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp1875219107110672856.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.tensorflow_libtensorflow-1.15.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/commons-logging_commons-logging-1.1.3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp8472967262725500022.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/commons-logging_commons-logging-1.1.3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/net.sf.trove4j_trove4j-3.0.3.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/net.sf.trove4j_trove4j-3.0.3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp8746380158152321343.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/net.sf.trove4j_trove4j-3.0.3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.google.code.gson_gson-2.3.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.google.code.gson_gson-2.3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp264085666451406497.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.google.code.gson_gson-2.3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.json4s_json4s-ext_2.11-3.5.3.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.json4s_json4s-ext_2.11-3.5.3.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp4190386425323430879.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.json4s_json4s-ext_2.11-3.5.3.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-core-1.11.603.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-core-1.11.603.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp6334795072003331302.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.amazonaws_aws-java-sdk-core-1.11.603.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-core-2.6.7.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-core-2.6.7.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp3526376508460519327.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.fasterxml.jackson.core_jackson-core-2.6.7.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-s3-1.11.603.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.amazonaws_aws-java-sdk-s3-1.11.603.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp8703528853685336766.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.amazonaws_aws-java-sdk-s3-1.11.603.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.typesafe_config-1.3.0.jar with timestamp 1620047197943
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.typesafe_config-1.3.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp1759787764733523998.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.typesafe_config-1.3.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.apache.httpcomponents_httpcore-4.4.11.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.apache.httpcomponents_httpcore-4.4.11.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp5281283819303571817.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.apache.httpcomponents_httpcore-4.4.11.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-annotations-2.6.0.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.fasterxml.jackson.core_jackson-annotations-2.6.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp7534845185499184221.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.fasterxml.jackson.core_jackson-annotations-2.6.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/com.amazonaws_jmespath-java-1.11.603.jar with timestamp 1620047197945
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/com.amazonaws_jmespath-java-1.11.603.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp8490591153916052612.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/com.amazonaws_jmespath-java-1.11.603.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/org.apache.hadoop_hadoop-aws-3.2.0.jar with timestamp 1620047197944
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/org.apache.hadoop_hadoop-aws-3.2.0.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp4982355453567610522.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/org.apache.hadoop_hadoop-aws-3.2.0.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/sparklyr-3.0-2.12.jar with timestamp 1620047197947
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp8292882551591374761.tmp
21/05/03 09:06:47 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/sparklyr-3.0-2.12.jar to class loader
21/05/03 09:06:47 INFO Executor: Fetching spark://localhost:50388/jars/it.unimi.dsi_fastutil-7.0.12.jar with timestamp 1620047197946
21/05/03 09:06:47 INFO Utils: Fetching spark://localhost:50388/jars/it.unimi.dsi_fastutil-7.0.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/fetchFileTemp3826999817428922862.tmp
21/05/03 09:06:48 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914/userFiles-fa13ac47-a35a-4f9f-84bf-4140f72fdbdb/it.unimi.dsi_fastutil-7.0.12.jar to class loader
21/05/03 09:06:48 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 09:06:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/05/03 09:06:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2684 bytes result sent to driver
21/05/03 09:06:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 1309 ms on localhost (executor driver) (1/1)
21/05/03 09:06:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 09:06:48 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 1.548 s
21/05/03 09:06:48 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 09:06:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 09:06:48 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 1.589899 s
21/05/03 09:06:48 INFO HiveMetaStore: 0: get_database: default
21/05/03 09:06:48 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 09:06:48 INFO HiveMetaStore: 0: get_database: default
21/05/03 09:06:48 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 09:06:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 09:06:48 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 09:06:48 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 09:06:48 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 09:06:48 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 09:06:48 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 09:06:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 09:06:48 INFO DAGScheduler: Missing parents: List()
21/05/03 09:06:48 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 09:06:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 09:06:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 09:06:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:50389 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 09:06:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 09:06:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 09:06:48 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 09:06:48 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 09:06:48 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 09:06:48 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 09:06:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 09:06:48 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 09:06:48 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 10 ms on localhost (executor driver) (1/1)
21/05/03 09:06:48 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 09:06:48 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.017 s
21/05/03 09:06:48 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 09:06:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 09:06:48 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.021461 s
21/05/03 09:36:38 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:50389 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 09:36:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:50389 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 11:06:38 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 11:06:38 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 11:06:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 11:06:38 INFO MemoryStore: MemoryStore cleared
21/05/03 11:06:38 INFO BlockManager: BlockManager stopped
21/05/03 11:06:38 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 11:06:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 11:06:38 INFO SparkContext: Successfully stopped SparkContext
21/05/03 11:06:38 INFO ShutdownHookManager: Shutdown hook called
21/05/03 11:06:38 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-5bd93907-0b26-41b4-9a54-6a43adf7033b
21/05/03 11:06:38 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1c0dced-e04a-44fa-9aa4-2ce9969b4914
21/05/03 11:42:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 11:42:29 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 11:42:29 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 11:42:29 INFO SecurityManager: Changing view acls groups to: 
21/05/03 11:42:29 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 11:42:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 11:42:29 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 11:42:29 INFO SparkContext: Running Spark version 3.0.1
21/05/03 11:42:29 INFO ResourceUtils: ==============================================================
21/05/03 11:42:29 INFO ResourceUtils: Resources for spark.driver:

21/05/03 11:42:29 INFO ResourceUtils: ==============================================================
21/05/03 11:42:29 INFO SparkContext: Submitted application: sparklyr
21/05/03 11:42:29 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 11:42:29 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 11:42:29 INFO SecurityManager: Changing view acls groups to: 
21/05/03 11:42:29 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 11:42:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 11:42:29 INFO Utils: Successfully started service 'sparkDriver' on port 52500.
21/05/03 11:42:30 INFO SparkEnv: Registering MapOutputTracker
21/05/03 11:42:30 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 11:42:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 11:42:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 11:42:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 11:42:30 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-e989f146-3bb9-4d23-b08f-20be988b8d47
21/05/03 11:42:30 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 11:42:30 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 11:42:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 11:42:30 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 11:42:30 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:52500/jars/sparklyr-3.0-2.12.jar with timestamp 1620056550385
21/05/03 11:42:30 INFO Executor: Starting executor ID driver on host localhost
21/05/03 11:42:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52501.
21/05/03 11:42:30 INFO NettyBlockTransferService: Server created on localhost:52501
21/05/03 11:42:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 11:42:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 52501, None)
21/05/03 11:42:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52501 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 52501, None)
21/05/03 11:42:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 52501, None)
21/05/03 11:42:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 52501, None)
21/05/03 11:42:30 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 11:42:30 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 11:42:30 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 11:42:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 11:42:32 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 11:42:33 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/b66100d7-77bb-40a8-9fcf-5dd67ce71356
21/05/03 11:42:33 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/b66100d7-77bb-40a8-9fcf-5dd67ce71356
21/05/03 11:42:33 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/b66100d7-77bb-40a8-9fcf-5dd67ce71356/_tmp_space.db
21/05/03 11:42:33 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 11:42:33 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 11:42:33 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 11:42:33 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 11:42:33 INFO ObjectStore: ObjectStore, initialize called
21/05/03 11:42:33 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 11:42:33 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 11:42:34 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 11:42:36 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 11:42:36 INFO ObjectStore: Initialized ObjectStore
21/05/03 11:42:36 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 11:42:36 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 11:42:36 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 11:42:36 INFO HiveMetaStore: Added admin role in metastore
21/05/03 11:42:36 INFO HiveMetaStore: Added public role in metastore
21/05/03 11:42:36 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 11:42:36 INFO HiveMetaStore: 0: get_all_functions
21/05/03 11:42:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 11:42:36 INFO HiveMetaStore: 0: get_database: default
21/05/03 11:42:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 11:42:36 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 11:42:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 11:42:36 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 11:42:36 INFO HiveMetaStore: 0: get_database: default
21/05/03 11:42:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 11:42:36 INFO HiveMetaStore: 0: get_database: default
21/05/03 11:42:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 11:42:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 11:42:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 11:42:37 INFO CodeGenerator: Code generated in 166.703455 ms
21/05/03 11:42:37 INFO CodeGenerator: Code generated in 11.553893 ms
21/05/03 11:42:37 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 11:42:37 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 11:42:37 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 11:42:37 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 11:42:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 11:42:37 INFO DAGScheduler: Missing parents: List()
21/05/03 11:42:37 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 11:42:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 11:42:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 11:42:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52501 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 11:42:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 11:42:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 11:42:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 11:42:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 11:42:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 11:42:37 INFO Executor: Fetching spark://localhost:52500/jars/sparklyr-3.0-2.12.jar with timestamp 1620056550385
21/05/03 11:42:37 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:52500 after 14 ms (0 ms spent in bootstraps)
21/05/03 11:42:37 INFO Utils: Fetching spark://localhost:52500/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-2787291e-4b0f-4421-8c18-774a7ccadbb3/userFiles-347cbe8d-1d90-469d-86da-43bb320f17ac/fetchFileTemp7751553932069517878.tmp
21/05/03 11:42:37 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-2787291e-4b0f-4421-8c18-774a7ccadbb3/userFiles-347cbe8d-1d90-469d-86da-43bb320f17ac/sparklyr-3.0-2.12.jar to class loader
21/05/03 11:42:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 11:42:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/05/03 11:42:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2684 bytes result sent to driver
21/05/03 11:42:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 300 ms on localhost (executor driver) (1/1)
21/05/03 11:42:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 11:42:38 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.638 s
21/05/03 11:42:38 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 11:42:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 11:42:38 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.681477 s
21/05/03 12:12:31 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:52501 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 12:38:43 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 12:38:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 12:38:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 12:38:43 INFO MemoryStore: MemoryStore cleared
21/05/03 12:38:43 INFO BlockManager: BlockManager stopped
21/05/03 12:38:43 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 12:38:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 12:38:43 INFO SparkContext: Successfully stopped SparkContext
21/05/03 12:38:43 INFO ShutdownHookManager: Shutdown hook called
21/05/03 12:38:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-49811a8b-b879-4b8a-ad2e-996faa2d33a0
21/05/03 12:38:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-2787291e-4b0f-4421-8c18-774a7ccadbb3
21/05/03 12:39:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 12:39:07 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 12:39:07 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 12:39:07 INFO SecurityManager: Changing view acls groups to: 
21/05/03 12:39:07 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 12:39:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 12:39:08 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 12:39:08 INFO SparkContext: Running Spark version 3.0.1
21/05/03 12:39:08 INFO ResourceUtils: ==============================================================
21/05/03 12:39:08 INFO ResourceUtils: Resources for spark.driver:

21/05/03 12:39:08 INFO ResourceUtils: ==============================================================
21/05/03 12:39:08 INFO SparkContext: Submitted application: sparklyr
21/05/03 12:39:08 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 12:39:08 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 12:39:08 INFO SecurityManager: Changing view acls groups to: 
21/05/03 12:39:08 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 12:39:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 12:39:08 INFO Utils: Successfully started service 'sparkDriver' on port 53432.
21/05/03 12:39:08 INFO SparkEnv: Registering MapOutputTracker
21/05/03 12:39:08 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 12:39:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 12:39:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 12:39:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 12:39:08 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-f3954b5f-6034-4c3b-942c-2ebdab1bd218
21/05/03 12:39:08 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 12:39:08 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 12:39:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 12:39:09 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 12:39:09 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:53432/jars/sparklyr-3.0-2.12.jar with timestamp 1620059949131
21/05/03 12:39:09 INFO Executor: Starting executor ID driver on host localhost
21/05/03 12:39:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53433.
21/05/03 12:39:09 INFO NettyBlockTransferService: Server created on localhost:53433
21/05/03 12:39:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 12:39:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 53433, None)
21/05/03 12:39:09 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53433 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 53433, None)
21/05/03 12:39:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 53433, None)
21/05/03 12:39:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 53433, None)
21/05/03 12:39:09 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 12:39:09 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 12:39:09 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 12:39:11 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 12:39:11 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 12:39:12 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/a6160864-5c50-4161-a447-4185323bfcfa
21/05/03 12:39:12 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/a6160864-5c50-4161-a447-4185323bfcfa
21/05/03 12:39:12 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/a6160864-5c50-4161-a447-4185323bfcfa/_tmp_space.db
21/05/03 12:39:12 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 12:39:12 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 12:39:12 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 12:39:12 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 12:39:12 INFO ObjectStore: ObjectStore, initialize called
21/05/03 12:39:12 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 12:39:12 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 12:39:13 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 12:39:14 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 12:39:14 INFO ObjectStore: Initialized ObjectStore
21/05/03 12:39:14 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 12:39:14 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 12:39:14 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 12:39:15 INFO HiveMetaStore: Added admin role in metastore
21/05/03 12:39:15 INFO HiveMetaStore: Added public role in metastore
21/05/03 12:39:15 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 12:39:15 INFO HiveMetaStore: 0: get_all_functions
21/05/03 12:39:15 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 12:39:15 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:39:15 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:39:15 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 12:39:15 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 12:39:15 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 12:39:15 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:39:15 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:39:15 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:39:15 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:39:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 12:39:15 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 12:39:16 INFO CodeGenerator: Code generated in 180.488651 ms
21/05/03 12:39:16 INFO CodeGenerator: Code generated in 11.448274 ms
21/05/03 12:39:16 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 12:39:16 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 12:39:16 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 12:39:16 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 12:39:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 12:39:16 INFO DAGScheduler: Missing parents: List()
21/05/03 12:39:16 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 12:39:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 12:39:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 12:39:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53433 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 12:39:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 12:39:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 12:39:16 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 12:39:16 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 12:39:16 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 12:39:16 INFO Executor: Fetching spark://localhost:53432/jars/sparklyr-3.0-2.12.jar with timestamp 1620059949131
21/05/03 12:39:16 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:53432 after 15 ms (0 ms spent in bootstraps)
21/05/03 12:39:16 INFO Utils: Fetching spark://localhost:53432/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-7eb9b5f0-4e5a-423a-82e2-f1c0c8b997f8/userFiles-03afcddc-652d-486a-a40d-14af96a2ba6d/fetchFileTemp8923968295953249360.tmp
21/05/03 12:39:16 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-7eb9b5f0-4e5a-423a-82e2-f1c0c8b997f8/userFiles-03afcddc-652d-486a-a40d-14af96a2ba6d/sparklyr-3.0-2.12.jar to class loader
21/05/03 12:39:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 12:39:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 12:39:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2684 bytes result sent to driver
21/05/03 12:39:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 312 ms on localhost (executor driver) (1/1)
21/05/03 12:39:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 12:39:16 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.603 s
21/05/03 12:39:16 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 12:39:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 12:39:16 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.644580 s
21/05/03 12:39:16 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:39:16 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:39:16 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:39:16 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:39:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 12:39:16 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 12:39:17 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 12:39:17 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 12:39:17 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 12:39:17 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 12:39:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 12:39:17 INFO DAGScheduler: Missing parents: List()
21/05/03 12:39:17 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 12:39:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 12:39:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 12:39:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53433 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 12:39:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 12:39:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 12:39:17 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 12:39:17 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 12:39:17 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 12:39:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 12:39:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 12:39:17 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 12:39:17 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 8 ms on localhost (executor driver) (1/1)
21/05/03 12:39:17 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 12:39:17 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.015 s
21/05/03 12:39:17 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 12:39:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 12:39:17 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.017837 s
21/05/03 12:58:13 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 12:58:13 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 12:58:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 12:58:13 INFO MemoryStore: MemoryStore cleared
21/05/03 12:58:13 INFO BlockManager: BlockManager stopped
21/05/03 12:58:13 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 12:58:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 12:58:13 INFO SparkContext: Successfully stopped SparkContext
21/05/03 12:58:13 INFO ShutdownHookManager: Shutdown hook called
21/05/03 12:58:13 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-7eb9b5f0-4e5a-423a-82e2-f1c0c8b997f8
21/05/03 12:58:13 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-403703ff-af93-4288-a25c-524b343926b6
21/05/03 12:59:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 12:59:02 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 12:59:02 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 12:59:02 INFO SecurityManager: Changing view acls groups to: 
21/05/03 12:59:02 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 12:59:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 12:59:03 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 12:59:03 INFO SparkContext: Running Spark version 3.0.1
21/05/03 12:59:03 INFO ResourceUtils: ==============================================================
21/05/03 12:59:03 INFO ResourceUtils: Resources for spark.driver:

21/05/03 12:59:03 INFO ResourceUtils: ==============================================================
21/05/03 12:59:03 INFO SparkContext: Submitted application: sparklyr
21/05/03 12:59:03 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 12:59:03 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 12:59:03 INFO SecurityManager: Changing view acls groups to: 
21/05/03 12:59:03 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 12:59:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 12:59:03 INFO Utils: Successfully started service 'sparkDriver' on port 54001.
21/05/03 12:59:03 INFO SparkEnv: Registering MapOutputTracker
21/05/03 12:59:04 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 12:59:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 12:59:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 12:59:04 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 12:59:04 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-4d05945c-8dc3-4146-9998-e49991ce2446
21/05/03 12:59:04 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 12:59:04 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 12:59:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 12:59:04 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 12:59:04 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:54001/jars/sparklyr-3.0-2.12.jar with timestamp 1620061144350
21/05/03 12:59:04 INFO Executor: Starting executor ID driver on host localhost
21/05/03 12:59:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54002.
21/05/03 12:59:04 INFO NettyBlockTransferService: Server created on localhost:54002
21/05/03 12:59:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 12:59:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 54002, None)
21/05/03 12:59:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54002 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 54002, None)
21/05/03 12:59:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 54002, None)
21/05/03 12:59:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 54002, None)
21/05/03 12:59:04 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 12:59:04 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 12:59:04 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 12:59:06 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 12:59:07 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 12:59:07 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/709cda93-9c37-45d3-a97a-261a2d47e093
21/05/03 12:59:07 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/709cda93-9c37-45d3-a97a-261a2d47e093
21/05/03 12:59:07 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/709cda93-9c37-45d3-a97a-261a2d47e093/_tmp_space.db
21/05/03 12:59:07 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 12:59:07 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 12:59:07 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 12:59:07 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 12:59:07 INFO ObjectStore: ObjectStore, initialize called
21/05/03 12:59:08 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 12:59:08 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 12:59:09 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 12:59:10 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 12:59:10 INFO ObjectStore: Initialized ObjectStore
21/05/03 12:59:10 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 12:59:10 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 12:59:10 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 12:59:10 INFO HiveMetaStore: Added admin role in metastore
21/05/03 12:59:10 INFO HiveMetaStore: Added public role in metastore
21/05/03 12:59:10 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 12:59:10 INFO HiveMetaStore: 0: get_all_functions
21/05/03 12:59:10 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 12:59:10 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:59:10 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:59:10 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 12:59:10 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 12:59:10 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 12:59:10 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:59:10 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:59:10 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:59:10 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:59:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 12:59:10 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 12:59:11 INFO CodeGenerator: Code generated in 174.333682 ms
21/05/03 12:59:11 INFO CodeGenerator: Code generated in 10.74157 ms
21/05/03 12:59:11 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 12:59:11 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 12:59:11 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 12:59:11 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 12:59:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 12:59:11 INFO DAGScheduler: Missing parents: List()
21/05/03 12:59:11 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 12:59:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 12:59:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 12:59:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54002 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 12:59:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 12:59:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 12:59:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 12:59:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 12:59:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 12:59:12 INFO Executor: Fetching spark://localhost:54001/jars/sparklyr-3.0-2.12.jar with timestamp 1620061144350
21/05/03 12:59:12 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:54001 after 14 ms (0 ms spent in bootstraps)
21/05/03 12:59:12 INFO Utils: Fetching spark://localhost:54001/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-10a4c1a3-4937-4df5-a1ee-0e7296a724f9/userFiles-7b342104-0161-44a6-a440-590d72154971/fetchFileTemp6497568111366335735.tmp
21/05/03 12:59:12 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-10a4c1a3-4937-4df5-a1ee-0e7296a724f9/userFiles-7b342104-0161-44a6-a440-590d72154971/sparklyr-3.0-2.12.jar to class loader
21/05/03 12:59:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 12:59:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/05/03 12:59:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 12:59:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 290 ms on localhost (executor driver) (1/1)
21/05/03 12:59:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 12:59:12 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.595 s
21/05/03 12:59:12 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 12:59:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 12:59:12 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.636234 s
21/05/03 12:59:12 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:59:12 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:59:12 INFO HiveMetaStore: 0: get_database: default
21/05/03 12:59:12 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 12:59:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 12:59:12 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 12:59:12 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:54002 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 12:59:12 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 12:59:12 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 12:59:12 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 12:59:12 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 12:59:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 12:59:12 INFO DAGScheduler: Missing parents: List()
21/05/03 12:59:12 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 12:59:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 12:59:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 12:59:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54002 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 12:59:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 12:59:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 12:59:12 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 12:59:12 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 12:59:12 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 12:59:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 12:59:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 12:59:12 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 12:59:12 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 7 ms on localhost (executor driver) (1/1)
21/05/03 12:59:12 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 12:59:12 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.013 s
21/05/03 12:59:12 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 12:59:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 12:59:12 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.016204 s
21/05/03 13:11:23 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 13:11:23 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 13:11:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 13:11:23 INFO MemoryStore: MemoryStore cleared
21/05/03 13:11:23 INFO BlockManager: BlockManager stopped
21/05/03 13:11:23 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 13:11:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 13:11:23 INFO SparkContext: Successfully stopped SparkContext
21/05/03 13:11:23 INFO ShutdownHookManager: Shutdown hook called
21/05/03 13:11:23 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-10a4c1a3-4937-4df5-a1ee-0e7296a724f9
21/05/03 13:11:23 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-484796dd-181e-48e6-8668-250c55fd10bc
21/05/03 13:12:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 13:12:19 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:12:19 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:12:19 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:12:19 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:12:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:12:19 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:12:20 INFO SparkContext: Running Spark version 3.0.1
21/05/03 13:12:20 INFO ResourceUtils: ==============================================================
21/05/03 13:12:20 INFO ResourceUtils: Resources for spark.driver:

21/05/03 13:12:20 INFO ResourceUtils: ==============================================================
21/05/03 13:12:20 INFO SparkContext: Submitted application: sparklyr
21/05/03 13:12:20 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:12:20 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:12:20 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:12:20 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:12:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:12:20 INFO Utils: Successfully started service 'sparkDriver' on port 54985.
21/05/03 13:12:20 INFO SparkEnv: Registering MapOutputTracker
21/05/03 13:12:20 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 13:12:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 13:12:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 13:12:20 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 13:12:20 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-d74851b2-3e4f-4258-bdcb-04d0c7ba18f3
21/05/03 13:12:20 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 13:12:20 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 13:12:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 13:12:20 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 13:12:20 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:54985/jars/sparklyr-3.0-2.12.jar with timestamp 1620061940577
21/05/03 13:12:20 INFO Executor: Starting executor ID driver on host localhost
21/05/03 13:12:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54986.
21/05/03 13:12:20 INFO NettyBlockTransferService: Server created on localhost:54986
21/05/03 13:12:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 13:12:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 54986, None)
21/05/03 13:12:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54986 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 54986, None)
21/05/03 13:12:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 54986, None)
21/05/03 13:12:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 54986, None)
21/05/03 13:12:20 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:12:20 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 13:12:20 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 13:12:23 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 13:12:23 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:12:23 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/cebfcc1f-da3c-4625-acb1-382145cefe5b
21/05/03 13:12:23 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/cebfcc1f-da3c-4625-acb1-382145cefe5b
21/05/03 13:12:23 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/cebfcc1f-da3c-4625-acb1-382145cefe5b/_tmp_space.db
21/05/03 13:12:23 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 13:12:24 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 13:12:24 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 13:12:24 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 13:12:24 INFO ObjectStore: ObjectStore, initialize called
21/05/03 13:12:24 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 13:12:24 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 13:12:25 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 13:12:26 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 13:12:26 INFO ObjectStore: Initialized ObjectStore
21/05/03 13:12:26 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 13:12:26 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 13:12:26 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 13:12:26 INFO HiveMetaStore: Added admin role in metastore
21/05/03 13:12:26 INFO HiveMetaStore: Added public role in metastore
21/05/03 13:12:26 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 13:12:26 INFO HiveMetaStore: 0: get_all_functions
21/05/03 13:12:26 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 13:12:26 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:12:26 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:12:26 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 13:12:26 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 13:12:26 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 13:12:26 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:12:26 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:12:26 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:12:26 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:12:26 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:12:26 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:12:27 INFO CodeGenerator: Code generated in 166.902837 ms
21/05/03 13:12:27 INFO CodeGenerator: Code generated in 10.357411 ms
21/05/03 13:12:27 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:12:27 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 13:12:27 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 13:12:27 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 13:12:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 13:12:27 INFO DAGScheduler: Missing parents: List()
21/05/03 13:12:27 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 13:12:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:12:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:12:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54986 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:12:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 13:12:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:12:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 13:12:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:12:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 13:12:28 INFO Executor: Fetching spark://localhost:54985/jars/sparklyr-3.0-2.12.jar with timestamp 1620061940577
21/05/03 13:12:28 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:54985 after 14 ms (0 ms spent in bootstraps)
21/05/03 13:12:28 INFO Utils: Fetching spark://localhost:54985/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-12f1f9a9-2fb3-4ad5-8a27-0001e4152f2d/userFiles-459f09b8-d65d-4b72-85bb-52b4096fe162/fetchFileTemp5165540833136966390.tmp
21/05/03 13:12:28 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-12f1f9a9-2fb3-4ad5-8a27-0001e4152f2d/userFiles-459f09b8-d65d-4b72-85bb-52b4096fe162/sparklyr-3.0-2.12.jar to class loader
21/05/03 13:12:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 13:12:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 13:12:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 285 ms on localhost (executor driver) (1/1)
21/05/03 13:12:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 13:12:28 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.527 s
21/05/03 13:12:28 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:12:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 13:12:28 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.564598 s
21/05/03 13:12:28 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:12:28 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:12:28 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:12:28 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:12:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:12:28 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:12:28 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:12:28 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 13:12:28 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 13:12:28 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 13:12:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 13:12:28 INFO DAGScheduler: Missing parents: List()
21/05/03 13:12:28 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 13:12:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:12:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:12:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54986 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:12:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 13:12:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:12:28 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 13:12:28 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:12:28 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 13:12:28 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 13:12:28 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 13:12:28 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 6 ms on localhost (executor driver) (1/1)
21/05/03 13:12:28 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 13:12:28 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.031 s
21/05/03 13:12:28 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:12:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 13:12:28 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.035436 s
21/05/03 13:12:28 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:54986 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:31:40 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 13:31:40 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 13:31:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 13:31:40 INFO MemoryStore: MemoryStore cleared
21/05/03 13:31:40 INFO BlockManager: BlockManager stopped
21/05/03 13:31:40 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 13:31:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 13:31:40 INFO SparkContext: Successfully stopped SparkContext
21/05/03 13:31:40 INFO ShutdownHookManager: Shutdown hook called
21/05/03 13:31:40 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a98ca65c-70f6-4732-b320-f03d57106d6b
21/05/03 13:31:40 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-12f1f9a9-2fb3-4ad5-8a27-0001e4152f2d
21/05/03 13:33:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 13:33:53 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:33:53 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:33:53 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:33:53 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:33:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:33:54 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:33:54 INFO SparkContext: Running Spark version 3.0.1
21/05/03 13:33:54 INFO ResourceUtils: ==============================================================
21/05/03 13:33:54 INFO ResourceUtils: Resources for spark.driver:

21/05/03 13:33:54 INFO ResourceUtils: ==============================================================
21/05/03 13:33:54 INFO SparkContext: Submitted application: sparklyr
21/05/03 13:33:54 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:33:54 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:33:54 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:33:54 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:33:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:33:54 INFO Utils: Successfully started service 'sparkDriver' on port 55475.
21/05/03 13:33:54 INFO SparkEnv: Registering MapOutputTracker
21/05/03 13:33:54 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 13:33:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 13:33:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 13:33:54 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 13:33:54 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-8649120c-9ccd-4325-96df-24873202b04b
21/05/03 13:33:54 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 13:33:54 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 13:33:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 13:33:55 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 13:33:55 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:55475/jars/sparklyr-3.0-2.12.jar with timestamp 1620063235149
21/05/03 13:33:55 INFO Executor: Starting executor ID driver on host localhost
21/05/03 13:33:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55477.
21/05/03 13:33:55 INFO NettyBlockTransferService: Server created on localhost:55477
21/05/03 13:33:55 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 13:33:55 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 55477, None)
21/05/03 13:33:55 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55477 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 55477, None)
21/05/03 13:33:55 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 55477, None)
21/05/03 13:33:55 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 55477, None)
21/05/03 13:33:55 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:33:55 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 13:33:55 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 13:33:57 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 13:33:57 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:33:58 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/505d33ea-c8e2-40bc-b48c-b790312f665f
21/05/03 13:33:58 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/505d33ea-c8e2-40bc-b48c-b790312f665f
21/05/03 13:33:58 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/505d33ea-c8e2-40bc-b48c-b790312f665f/_tmp_space.db
21/05/03 13:33:58 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 13:33:58 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 13:33:58 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 13:33:58 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 13:33:58 INFO ObjectStore: ObjectStore, initialize called
21/05/03 13:33:58 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 13:33:58 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 13:33:59 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 13:34:00 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 13:34:00 INFO ObjectStore: Initialized ObjectStore
21/05/03 13:34:00 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 13:34:00 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 13:34:00 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 13:34:01 INFO HiveMetaStore: Added admin role in metastore
21/05/03 13:34:01 INFO HiveMetaStore: Added public role in metastore
21/05/03 13:34:01 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 13:34:01 INFO HiveMetaStore: 0: get_all_functions
21/05/03 13:34:01 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 13:34:01 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:34:01 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:34:01 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 13:34:01 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 13:34:01 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 13:34:01 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:34:01 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:34:01 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:34:01 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:34:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:34:01 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:34:02 INFO CodeGenerator: Code generated in 163.812027 ms
21/05/03 13:34:02 INFO CodeGenerator: Code generated in 9.934509 ms
21/05/03 13:34:02 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:34:02 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 13:34:02 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 13:34:02 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 13:34:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 13:34:02 INFO DAGScheduler: Missing parents: List()
21/05/03 13:34:02 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 13:34:02 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:34:02 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:34:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55477 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:34:02 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 13:34:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:34:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 13:34:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:34:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 13:34:02 INFO Executor: Fetching spark://localhost:55475/jars/sparklyr-3.0-2.12.jar with timestamp 1620063235149
21/05/03 13:34:02 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:55475 after 14 ms (0 ms spent in bootstraps)
21/05/03 13:34:02 INFO Utils: Fetching spark://localhost:55475/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-60b843c2-1b3a-4b6f-9ce9-15cfa19ebd63/userFiles-4076e07e-331d-41c1-86a2-cc543f0744f4/fetchFileTemp4211403954103139419.tmp
21/05/03 13:34:02 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-60b843c2-1b3a-4b6f-9ce9-15cfa19ebd63/userFiles-4076e07e-331d-41c1-86a2-cc543f0744f4/sparklyr-3.0-2.12.jar to class loader
21/05/03 13:34:02 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:34:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 13:34:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 13:34:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 276 ms on localhost (executor driver) (1/1)
21/05/03 13:34:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 13:34:02 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.551 s
21/05/03 13:34:02 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:34:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 13:34:02 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.587938 s
21/05/03 13:34:02 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:34:02 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:34:02 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:34:02 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:34:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:34:02 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:34:02 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:34:02 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 13:34:02 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 13:34:02 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 13:34:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 13:34:02 INFO DAGScheduler: Missing parents: List()
21/05/03 13:34:02 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 13:34:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:34:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:34:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55477 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:34:02 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 13:34:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:34:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 13:34:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:34:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 13:34:02 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:34:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 13:34:02 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 13:34:02 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 6 ms on localhost (executor driver) (1/1)
21/05/03 13:34:02 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 13:34:02 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.013 s
21/05/03 13:34:02 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:34:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 13:34:02 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.016480 s
21/05/03 13:35:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:55477 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:35:55 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:55477 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:42:38 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 13:42:38 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 13:42:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 13:42:38 INFO MemoryStore: MemoryStore cleared
21/05/03 13:42:38 INFO BlockManager: BlockManager stopped
21/05/03 13:42:38 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 13:42:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 13:42:38 INFO SparkContext: Successfully stopped SparkContext
21/05/03 13:42:38 INFO ShutdownHookManager: Shutdown hook called
21/05/03 13:42:38 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-04e78920-7d83-4b5e-b889-28060dfb8a86
21/05/03 13:42:38 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-60b843c2-1b3a-4b6f-9ce9-15cfa19ebd63
21/05/03 13:43:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 13:43:28 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:43:28 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:43:28 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:43:28 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:43:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:43:29 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:43:29 INFO SparkContext: Running Spark version 3.0.1
21/05/03 13:43:29 INFO ResourceUtils: ==============================================================
21/05/03 13:43:29 INFO ResourceUtils: Resources for spark.driver:

21/05/03 13:43:29 INFO ResourceUtils: ==============================================================
21/05/03 13:43:29 INFO SparkContext: Submitted application: sparklyr
21/05/03 13:43:29 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:43:29 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:43:29 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:43:29 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:43:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:43:29 INFO Utils: Successfully started service 'sparkDriver' on port 55886.
21/05/03 13:43:29 INFO SparkEnv: Registering MapOutputTracker
21/05/03 13:43:29 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 13:43:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 13:43:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 13:43:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 13:43:30 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-352a5ad7-e36c-4a3e-9ff6-05b486bf5a7e
21/05/03 13:43:30 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 13:43:30 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 13:43:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 13:43:30 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 13:43:30 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:55886/jars/sparklyr-3.0-2.12.jar with timestamp 1620063810310
21/05/03 13:43:30 INFO Executor: Starting executor ID driver on host localhost
21/05/03 13:43:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55887.
21/05/03 13:43:30 INFO NettyBlockTransferService: Server created on localhost:55887
21/05/03 13:43:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 13:43:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 55887, None)
21/05/03 13:43:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:55887 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 55887, None)
21/05/03 13:43:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 55887, None)
21/05/03 13:43:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 55887, None)
21/05/03 13:43:30 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:43:30 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 13:43:30 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 13:43:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 13:43:32 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:43:33 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/23eb9f4f-6720-47fb-ac91-bd6cd146dccc
21/05/03 13:43:33 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/23eb9f4f-6720-47fb-ac91-bd6cd146dccc
21/05/03 13:43:33 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/23eb9f4f-6720-47fb-ac91-bd6cd146dccc/_tmp_space.db
21/05/03 13:43:33 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 13:43:33 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 13:43:33 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 13:43:33 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 13:43:33 INFO ObjectStore: ObjectStore, initialize called
21/05/03 13:43:33 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 13:43:33 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 13:43:34 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 13:43:35 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 13:43:35 INFO ObjectStore: Initialized ObjectStore
21/05/03 13:43:35 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 13:43:35 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 13:43:35 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 13:43:36 INFO HiveMetaStore: Added admin role in metastore
21/05/03 13:43:36 INFO HiveMetaStore: Added public role in metastore
21/05/03 13:43:36 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 13:43:36 INFO HiveMetaStore: 0: get_all_functions
21/05/03 13:43:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 13:43:36 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:43:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:43:36 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 13:43:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 13:43:36 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 13:43:36 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:43:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:43:36 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:43:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:43:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:43:36 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:43:37 INFO CodeGenerator: Code generated in 162.633674 ms
21/05/03 13:43:37 INFO CodeGenerator: Code generated in 10.234067 ms
21/05/03 13:43:37 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:43:37 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 13:43:37 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 13:43:37 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 13:43:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 13:43:37 INFO DAGScheduler: Missing parents: List()
21/05/03 13:43:37 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 13:43:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:43:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:43:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:55887 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:43:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 13:43:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:43:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 13:43:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:43:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 13:43:37 INFO Executor: Fetching spark://localhost:55886/jars/sparklyr-3.0-2.12.jar with timestamp 1620063810310
21/05/03 13:43:37 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:55886 after 15 ms (0 ms spent in bootstraps)
21/05/03 13:43:37 INFO Utils: Fetching spark://localhost:55886/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-213e08ad-d562-4267-8b73-2e7712aa9b15/userFiles-79fb2bb8-a8fa-41bb-b049-6d6bc27bdd8a/fetchFileTemp107034832506048465.tmp
21/05/03 13:43:37 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-213e08ad-d562-4267-8b73-2e7712aa9b15/userFiles-79fb2bb8-a8fa-41bb-b049-6d6bc27bdd8a/sparklyr-3.0-2.12.jar to class loader
21/05/03 13:43:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:43:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 13:43:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 13:43:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 275 ms on localhost (executor driver) (1/1)
21/05/03 13:43:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 13:43:37 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.539 s
21/05/03 13:43:37 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:43:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 13:43:37 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.585511 s
21/05/03 13:43:37 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:43:37 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:43:37 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:43:37 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:43:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:43:37 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:43:37 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:55887 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:43:37 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:43:37 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 13:43:37 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 13:43:37 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 13:43:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 13:43:37 INFO DAGScheduler: Missing parents: List()
21/05/03 13:43:37 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 13:43:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:43:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:43:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:55887 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:43:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 13:43:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:43:37 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 13:43:37 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:43:37 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 13:43:37 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:43:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 13:43:37 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 13:43:37 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 7 ms on localhost (executor driver) (1/1)
21/05/03 13:43:37 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 13:43:37 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.013 s
21/05/03 13:43:37 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:43:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 13:43:37 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.016170 s
21/05/03 13:45:27 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 13:45:27 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 13:45:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 13:45:27 INFO MemoryStore: MemoryStore cleared
21/05/03 13:45:27 INFO BlockManager: BlockManager stopped
21/05/03 13:45:27 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 13:45:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 13:45:27 INFO SparkContext: Successfully stopped SparkContext
21/05/03 13:45:27 INFO ShutdownHookManager: Shutdown hook called
21/05/03 13:45:27 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-018d33a4-d108-41f1-bd7b-cce153ec1185
21/05/03 13:45:27 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-213e08ad-d562-4267-8b73-2e7712aa9b15
21/05/03 13:46:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 13:46:05 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:46:05 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:46:05 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:46:05 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:46:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:46:06 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:46:06 INFO SparkContext: Running Spark version 3.0.1
21/05/03 13:46:06 INFO ResourceUtils: ==============================================================
21/05/03 13:46:06 INFO ResourceUtils: Resources for spark.driver:

21/05/03 13:46:06 INFO ResourceUtils: ==============================================================
21/05/03 13:46:06 INFO SparkContext: Submitted application: sparklyr
21/05/03 13:46:06 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 13:46:06 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 13:46:06 INFO SecurityManager: Changing view acls groups to: 
21/05/03 13:46:06 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 13:46:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 13:46:06 INFO Utils: Successfully started service 'sparkDriver' on port 56398.
21/05/03 13:46:06 INFO SparkEnv: Registering MapOutputTracker
21/05/03 13:46:06 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 13:46:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 13:46:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 13:46:06 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 13:46:06 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-3968707b-0b45-4e32-888e-d8e54f1ce28a
21/05/03 13:46:06 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 13:46:06 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 13:46:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 13:46:07 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 13:46:07 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:56398/jars/sparklyr-3.0-2.12.jar with timestamp 1620063967230
21/05/03 13:46:07 INFO Executor: Starting executor ID driver on host localhost
21/05/03 13:46:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56399.
21/05/03 13:46:07 INFO NettyBlockTransferService: Server created on localhost:56399
21/05/03 13:46:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 13:46:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 56399, None)
21/05/03 13:46:07 INFO BlockManagerMasterEndpoint: Registering block manager localhost:56399 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 56399, None)
21/05/03 13:46:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 56399, None)
21/05/03 13:46:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 56399, None)
21/05/03 13:46:07 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:46:07 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 13:46:07 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 13:46:09 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 13:46:10 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 13:46:10 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/141cc042-cffc-4fee-8cbb-399120c61c8e
21/05/03 13:46:10 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/141cc042-cffc-4fee-8cbb-399120c61c8e
21/05/03 13:46:10 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/141cc042-cffc-4fee-8cbb-399120c61c8e/_tmp_space.db
21/05/03 13:46:10 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 13:46:10 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 13:46:10 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 13:46:10 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 13:46:10 INFO ObjectStore: ObjectStore, initialize called
21/05/03 13:46:10 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 13:46:10 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 13:46:11 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 13:46:13 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 13:46:13 INFO ObjectStore: Initialized ObjectStore
21/05/03 13:46:13 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 13:46:13 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@192.168.0.8
21/05/03 13:46:13 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 13:46:13 INFO HiveMetaStore: Added admin role in metastore
21/05/03 13:46:13 INFO HiveMetaStore: Added public role in metastore
21/05/03 13:46:13 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 13:46:13 INFO HiveMetaStore: 0: get_all_functions
21/05/03 13:46:13 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 13:46:13 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:46:13 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:46:13 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 13:46:13 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 13:46:13 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 13:46:13 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:46:13 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:46:13 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:46:13 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:46:13 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:46:13 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:46:14 INFO CodeGenerator: Code generated in 162.583159 ms
21/05/03 13:46:14 INFO CodeGenerator: Code generated in 11.178219 ms
21/05/03 13:46:14 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:46:14 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 13:46:14 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 13:46:14 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 13:46:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 13:46:14 INFO DAGScheduler: Missing parents: List()
21/05/03 13:46:14 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 13:46:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:46:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:46:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:56399 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:46:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 13:46:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:46:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 13:46:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:46:14 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 13:46:14 INFO Executor: Fetching spark://localhost:56398/jars/sparklyr-3.0-2.12.jar with timestamp 1620063967230
21/05/03 13:46:14 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:56398 after 15 ms (0 ms spent in bootstraps)
21/05/03 13:46:14 INFO Utils: Fetching spark://localhost:56398/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-e7b8b992-aa09-4d59-8a3f-d1baa68ee9cc/userFiles-fc3b488f-a74b-4907-9a5e-b58a9e22427b/fetchFileTemp4799408877759184395.tmp
21/05/03 13:46:14 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-e7b8b992-aa09-4d59-8a3f-d1baa68ee9cc/userFiles-fc3b488f-a74b-4907-9a5e-b58a9e22427b/sparklyr-3.0-2.12.jar to class loader
21/05/03 13:46:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:46:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 13:46:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 13:46:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 278 ms on localhost (executor driver) (1/1)
21/05/03 13:46:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 13:46:14 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.534 s
21/05/03 13:46:14 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:46:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 13:46:14 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.570681 s
21/05/03 13:46:14 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:46:14 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:46:14 INFO HiveMetaStore: 0: get_database: default
21/05/03 13:46:14 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 13:46:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 13:46:14 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 13:46:15 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 13:46:15 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 13:46:15 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 13:46:15 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 13:46:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 13:46:15 INFO DAGScheduler: Missing parents: List()
21/05/03 13:46:15 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 13:46:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 13:46:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 13:46:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:56399 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 13:46:15 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 13:46:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 13:46:15 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 13:46:15 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 13:46:15 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 13:46:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 13:46:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 13:46:15 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 13:46:15 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 7 ms on localhost (executor driver) (1/1)
21/05/03 13:46:15 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 13:46:15 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.013 s
21/05/03 13:46:15 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 13:46:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 13:46:15 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.016118 s
21/05/03 14:00:17 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 14:00:17 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 14:00:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 14:00:17 INFO MemoryStore: MemoryStore cleared
21/05/03 14:00:17 INFO BlockManager: BlockManager stopped
21/05/03 14:00:17 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 14:00:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 14:00:17 INFO SparkContext: Successfully stopped SparkContext
21/05/03 14:00:17 INFO ShutdownHookManager: Shutdown hook called
21/05/03 14:00:17 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-5f9726e4-cb4a-4440-a1e4-a86732243997
21/05/03 14:00:17 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-e7b8b992-aa09-4d59-8a3f-d1baa68ee9cc
21/05/03 14:01:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 14:01:50 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 14:01:50 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 14:01:50 INFO SecurityManager: Changing view acls groups to: 
21/05/03 14:01:50 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 14:01:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 14:01:50 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 14:01:50 INFO SparkContext: Running Spark version 3.0.1
21/05/03 14:01:50 INFO ResourceUtils: ==============================================================
21/05/03 14:01:50 INFO ResourceUtils: Resources for spark.driver:

21/05/03 14:01:50 INFO ResourceUtils: ==============================================================
21/05/03 14:01:50 INFO SparkContext: Submitted application: sparklyr
21/05/03 14:01:50 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 14:01:50 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 14:01:50 INFO SecurityManager: Changing view acls groups to: 
21/05/03 14:01:50 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 14:01:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 14:01:51 INFO Utils: Successfully started service 'sparkDriver' on port 57130.
21/05/03 14:01:51 INFO SparkEnv: Registering MapOutputTracker
21/05/03 14:01:51 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 14:01:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 14:01:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 14:01:51 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 14:01:51 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-ee4b3ad4-f7be-4fac-ab96-34ba376ac24c
21/05/03 14:01:51 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 14:01:51 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 14:01:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 14:01:51 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 14:01:51 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:57130/jars/sparklyr-3.0-2.12.jar with timestamp 1620064911401
21/05/03 14:01:51 INFO Executor: Starting executor ID driver on host localhost
21/05/03 14:01:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57131.
21/05/03 14:01:51 INFO NettyBlockTransferService: Server created on localhost:57131
21/05/03 14:01:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 14:01:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 57131, None)
21/05/03 14:01:51 INFO BlockManagerMasterEndpoint: Registering block manager localhost:57131 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 57131, None)
21/05/03 14:01:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 57131, None)
21/05/03 14:01:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 57131, None)
21/05/03 14:01:51 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 14:01:51 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 14:01:51 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 14:01:54 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 14:01:54 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 14:01:54 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/d80ac86a-e4e3-4546-bdb8-a5d5ad737ac2
21/05/03 14:01:54 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/d80ac86a-e4e3-4546-bdb8-a5d5ad737ac2
21/05/03 14:01:54 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/d80ac86a-e4e3-4546-bdb8-a5d5ad737ac2/_tmp_space.db
21/05/03 14:01:54 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 14:01:54 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 14:01:54 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 14:01:54 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 14:01:55 INFO ObjectStore: ObjectStore, initialize called
21/05/03 14:01:55 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 14:01:55 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 14:01:56 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 14:01:57 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 14:01:57 INFO ObjectStore: Initialized ObjectStore
21/05/03 14:01:57 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 14:01:57 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 14:01:57 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 14:01:57 INFO HiveMetaStore: Added admin role in metastore
21/05/03 14:01:57 INFO HiveMetaStore: Added public role in metastore
21/05/03 14:01:57 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 14:01:57 INFO HiveMetaStore: 0: get_all_functions
21/05/03 14:01:57 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 14:01:57 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:01:57 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:01:57 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 14:01:57 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 14:01:57 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 14:01:57 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:01:57 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:01:57 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:01:57 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:01:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 14:01:57 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 14:01:58 INFO CodeGenerator: Code generated in 163.802312 ms
21/05/03 14:01:58 INFO CodeGenerator: Code generated in 11.051084 ms
21/05/03 14:01:58 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 14:01:58 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 14:01:58 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 14:01:58 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 14:01:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 14:01:58 INFO DAGScheduler: Missing parents: List()
21/05/03 14:01:58 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 14:01:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 14:01:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 14:01:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:57131 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 14:01:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 14:01:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 14:01:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 14:01:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 14:01:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 14:01:58 INFO Executor: Fetching spark://localhost:57130/jars/sparklyr-3.0-2.12.jar with timestamp 1620064911401
21/05/03 14:01:58 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:57130 after 14 ms (0 ms spent in bootstraps)
21/05/03 14:01:58 INFO Utils: Fetching spark://localhost:57130/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-bc0fe5eb-9b91-4c25-94e7-a58e12ff8a14/userFiles-8ef204cc-83a0-4da0-b0c4-2466afd9c067/fetchFileTemp6227212088418206766.tmp
21/05/03 14:01:59 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-bc0fe5eb-9b91-4c25-94e7-a58e12ff8a14/userFiles-8ef204cc-83a0-4da0-b0c4-2466afd9c067/sparklyr-3.0-2.12.jar to class loader
21/05/03 14:01:59 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 14:01:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 14:01:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 14:01:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 271 ms on localhost (executor driver) (1/1)
21/05/03 14:01:59 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 14:01:59 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.576 s
21/05/03 14:01:59 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 14:01:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 14:01:59 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.629308 s
21/05/03 14:02:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:57131 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 14:39:28 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 14:39:28 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 14:39:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 14:39:28 INFO MemoryStore: MemoryStore cleared
21/05/03 14:39:28 INFO BlockManager: BlockManager stopped
21/05/03 14:39:28 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 14:39:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 14:39:28 INFO SparkContext: Successfully stopped SparkContext
21/05/03 14:39:28 INFO ShutdownHookManager: Shutdown hook called
21/05/03 14:39:28 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-bc0fe5eb-9b91-4c25-94e7-a58e12ff8a14
21/05/03 14:39:28 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-c68bbdc8-e6c0-4579-a1c9-7fee185e00db
21/05/03 14:45:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 14:45:09 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 14:45:09 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 14:45:09 INFO SecurityManager: Changing view acls groups to: 
21/05/03 14:45:09 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 14:45:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 14:45:10 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 14:45:10 INFO SparkContext: Running Spark version 3.0.1
21/05/03 14:45:10 INFO ResourceUtils: ==============================================================
21/05/03 14:45:10 INFO ResourceUtils: Resources for spark.driver:

21/05/03 14:45:10 INFO ResourceUtils: ==============================================================
21/05/03 14:45:10 INFO SparkContext: Submitted application: sparklyr
21/05/03 14:45:10 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 14:45:10 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 14:45:10 INFO SecurityManager: Changing view acls groups to: 
21/05/03 14:45:10 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 14:45:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 14:45:10 INFO Utils: Successfully started service 'sparkDriver' on port 58381.
21/05/03 14:45:10 INFO SparkEnv: Registering MapOutputTracker
21/05/03 14:45:10 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 14:45:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 14:45:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 14:45:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 14:45:10 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-68718138-f67d-40d0-807e-ca5f2b4d77d4
21/05/03 14:45:10 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 14:45:10 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 14:45:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 14:45:11 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 14:45:11 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:58381/jars/sparklyr-3.0-2.12.jar with timestamp 1620067511047
21/05/03 14:45:11 INFO Executor: Starting executor ID driver on host localhost
21/05/03 14:45:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58382.
21/05/03 14:45:11 INFO NettyBlockTransferService: Server created on localhost:58382
21/05/03 14:45:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 14:45:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 58382, None)
21/05/03 14:45:11 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58382 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 58382, None)
21/05/03 14:45:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 58382, None)
21/05/03 14:45:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 58382, None)
21/05/03 14:45:11 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 14:45:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 14:45:11 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 14:45:14 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 14:45:14 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 14:45:14 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/34f226db-5629-4ab5-9df9-3f1494a04e82
21/05/03 14:45:14 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/34f226db-5629-4ab5-9df9-3f1494a04e82
21/05/03 14:45:14 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/34f226db-5629-4ab5-9df9-3f1494a04e82/_tmp_space.db
21/05/03 14:45:14 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 14:45:15 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 14:45:15 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 14:45:15 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 14:45:15 INFO ObjectStore: ObjectStore, initialize called
21/05/03 14:45:15 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 14:45:15 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 14:45:16 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 14:45:17 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 14:45:17 INFO ObjectStore: Initialized ObjectStore
21/05/03 14:45:17 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 14:45:17 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 14:45:17 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 14:45:17 INFO HiveMetaStore: Added admin role in metastore
21/05/03 14:45:17 INFO HiveMetaStore: Added public role in metastore
21/05/03 14:45:17 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 14:45:17 INFO HiveMetaStore: 0: get_all_functions
21/05/03 14:45:17 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 14:45:17 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:45:17 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:45:17 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 14:45:17 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 14:45:17 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 14:45:17 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:45:17 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:45:17 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:45:17 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:45:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 14:45:17 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 14:45:18 INFO CodeGenerator: Code generated in 174.603683 ms
21/05/03 14:45:18 INFO CodeGenerator: Code generated in 11.485796 ms
21/05/03 14:45:18 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 14:45:18 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 14:45:18 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 14:45:18 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 14:45:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 14:45:18 INFO DAGScheduler: Missing parents: List()
21/05/03 14:45:18 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 14:45:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 14:45:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 14:45:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:58382 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 14:45:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 14:45:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 14:45:19 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 14:45:19 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 14:45:19 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 14:45:19 INFO Executor: Fetching spark://localhost:58381/jars/sparklyr-3.0-2.12.jar with timestamp 1620067511047
21/05/03 14:45:19 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:58381 after 16 ms (0 ms spent in bootstraps)
21/05/03 14:45:19 INFO Utils: Fetching spark://localhost:58381/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1d2899f-14a1-45d7-a55e-b76291edc4ef/userFiles-ebb372dd-5a43-4280-bfbc-f8efacfaf209/fetchFileTemp2122953450113070018.tmp
21/05/03 14:45:19 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1d2899f-14a1-45d7-a55e-b76291edc4ef/userFiles-ebb372dd-5a43-4280-bfbc-f8efacfaf209/sparklyr-3.0-2.12.jar to class loader
21/05/03 14:45:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 14:45:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 14:45:19 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2684 bytes result sent to driver
21/05/03 14:45:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 303 ms on localhost (executor driver) (1/1)
21/05/03 14:45:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 14:45:19 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.617 s
21/05/03 14:45:19 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 14:45:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 14:45:19 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.654588 s
21/05/03 14:54:54 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 14:54:54 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 14:54:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 14:54:54 INFO MemoryStore: MemoryStore cleared
21/05/03 14:54:54 INFO BlockManager: BlockManager stopped
21/05/03 14:54:54 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 14:54:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 14:54:54 INFO SparkContext: Successfully stopped SparkContext
21/05/03 14:54:54 INFO ShutdownHookManager: Shutdown hook called
21/05/03 14:54:54 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a1d2899f-14a1-45d7-a55e-b76291edc4ef
21/05/03 14:54:54 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-1ca7d06d-93d8-443d-839d-2c64f8090a4b
21/05/03 14:56:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 14:56:12 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 14:56:12 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 14:56:12 INFO SecurityManager: Changing view acls groups to: 
21/05/03 14:56:12 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 14:56:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 14:56:12 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 14:56:12 INFO SparkContext: Running Spark version 3.0.1
21/05/03 14:56:12 INFO ResourceUtils: ==============================================================
21/05/03 14:56:12 INFO ResourceUtils: Resources for spark.driver:

21/05/03 14:56:12 INFO ResourceUtils: ==============================================================
21/05/03 14:56:12 INFO SparkContext: Submitted application: sparklyr
21/05/03 14:56:13 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 14:56:13 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 14:56:13 INFO SecurityManager: Changing view acls groups to: 
21/05/03 14:56:13 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 14:56:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 14:56:13 INFO Utils: Successfully started service 'sparkDriver' on port 59135.
21/05/03 14:56:13 INFO SparkEnv: Registering MapOutputTracker
21/05/03 14:56:13 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 14:56:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 14:56:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 14:56:13 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 14:56:13 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-f0332ec6-d88e-48a2-bcd7-62e0f55946fe
21/05/03 14:56:13 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 14:56:13 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 14:56:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 14:56:13 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 14:56:13 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:59135/jars/sparklyr-3.0-2.12.jar with timestamp 1620068173458
21/05/03 14:56:13 INFO Executor: Starting executor ID driver on host localhost
21/05/03 14:56:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59136.
21/05/03 14:56:13 INFO NettyBlockTransferService: Server created on localhost:59136
21/05/03 14:56:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 14:56:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 59136, None)
21/05/03 14:56:13 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59136 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 59136, None)
21/05/03 14:56:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 59136, None)
21/05/03 14:56:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 59136, None)
21/05/03 14:56:13 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 14:56:13 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 14:56:13 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 14:56:16 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 14:56:16 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 14:56:17 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/9e0874fb-d58a-410b-8c9c-43e447cdd276
21/05/03 14:56:17 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/9e0874fb-d58a-410b-8c9c-43e447cdd276
21/05/03 14:56:17 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/9e0874fb-d58a-410b-8c9c-43e447cdd276/_tmp_space.db
21/05/03 14:56:17 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 14:56:17 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 14:56:17 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 14:56:17 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 14:56:17 INFO ObjectStore: ObjectStore, initialize called
21/05/03 14:56:17 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 14:56:17 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 14:56:18 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 14:56:19 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 14:56:19 INFO ObjectStore: Initialized ObjectStore
21/05/03 14:56:19 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 14:56:20 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 14:56:20 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 14:56:20 INFO HiveMetaStore: Added admin role in metastore
21/05/03 14:56:20 INFO HiveMetaStore: Added public role in metastore
21/05/03 14:56:20 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 14:56:20 INFO HiveMetaStore: 0: get_all_functions
21/05/03 14:56:20 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 14:56:20 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:56:20 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:56:20 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 14:56:20 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 14:56:20 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 14:56:20 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:56:20 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:56:20 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:56:20 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:56:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 14:56:20 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 14:56:21 INFO CodeGenerator: Code generated in 175.660755 ms
21/05/03 14:56:21 INFO CodeGenerator: Code generated in 11.554265 ms
21/05/03 14:56:21 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 14:56:21 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 14:56:21 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 14:56:21 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 14:56:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 14:56:21 INFO DAGScheduler: Missing parents: List()
21/05/03 14:56:21 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 14:56:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 14:56:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 14:56:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59136 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 14:56:21 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 14:56:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 14:56:21 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 14:56:21 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 14:56:21 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 14:56:21 INFO Executor: Fetching spark://localhost:59135/jars/sparklyr-3.0-2.12.jar with timestamp 1620068173458
21/05/03 14:56:21 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:59135 after 14 ms (0 ms spent in bootstraps)
21/05/03 14:56:21 INFO Utils: Fetching spark://localhost:59135/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-50694209-2022-406c-bd29-8699a85ffc84/userFiles-4088a96b-61d3-413f-a1e2-5d2835f5cbd0/fetchFileTemp6989651258524277813.tmp
21/05/03 14:56:21 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-50694209-2022-406c-bd29-8699a85ffc84/userFiles-4088a96b-61d3-413f-a1e2-5d2835f5cbd0/sparklyr-3.0-2.12.jar to class loader
21/05/03 14:56:21 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 14:56:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 14:56:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 14:56:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 292 ms on localhost (executor driver) (1/1)
21/05/03 14:56:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 14:56:21 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.460 s
21/05/03 14:56:21 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 14:56:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 14:56:21 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.495051 s
21/05/03 14:56:21 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:56:21 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:56:21 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:56:21 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:56:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 14:56:21 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 14:56:22 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:59136 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 14:56:22 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 14:56:22 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 14:56:22 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 14:56:22 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 14:56:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 14:56:22 INFO DAGScheduler: Missing parents: List()
21/05/03 14:56:22 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 14:56:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 14:56:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 14:56:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:59136 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 14:56:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 14:56:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 14:56:22 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 14:56:22 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 14:56:22 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 14:56:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 14:56:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 14:56:22 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 14:56:22 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 6 ms on localhost (executor driver) (1/1)
21/05/03 14:56:22 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 14:56:22 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.013 s
21/05/03 14:56:22 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 14:56:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 14:56:22 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.016221 s
21/05/03 14:56:29 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 14:56:29 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 14:56:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 14:56:29 INFO MemoryStore: MemoryStore cleared
21/05/03 14:56:29 INFO BlockManager: BlockManager stopped
21/05/03 14:56:29 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 14:56:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 14:56:29 INFO SparkContext: Successfully stopped SparkContext
21/05/03 14:56:29 INFO ShutdownHookManager: Shutdown hook called
21/05/03 14:56:29 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-50694209-2022-406c-bd29-8699a85ffc84
21/05/03 14:56:29 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-53364e97-dbe1-4bb3-89a7-e33fb6978b9b
21/05/03 14:57:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 14:57:50 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 14:57:50 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 14:57:50 INFO SecurityManager: Changing view acls groups to: 
21/05/03 14:57:50 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 14:57:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 14:57:50 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 14:57:50 INFO SparkContext: Running Spark version 3.0.1
21/05/03 14:57:51 INFO ResourceUtils: ==============================================================
21/05/03 14:57:51 INFO ResourceUtils: Resources for spark.driver:

21/05/03 14:57:51 INFO ResourceUtils: ==============================================================
21/05/03 14:57:51 INFO SparkContext: Submitted application: sparklyr
21/05/03 14:57:51 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 14:57:51 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 14:57:51 INFO SecurityManager: Changing view acls groups to: 
21/05/03 14:57:51 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 14:57:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 14:57:51 INFO Utils: Successfully started service 'sparkDriver' on port 59480.
21/05/03 14:57:51 INFO SparkEnv: Registering MapOutputTracker
21/05/03 14:57:51 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 14:57:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 14:57:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 14:57:51 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 14:57:51 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-dde88b8e-162e-43db-a134-10d115c943ab
21/05/03 14:57:51 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 14:57:51 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 14:57:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 14:57:51 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 14:57:51 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:59480/jars/sparklyr-3.0-2.12.jar with timestamp 1620068271511
21/05/03 14:57:51 INFO Executor: Starting executor ID driver on host localhost
21/05/03 14:57:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59481.
21/05/03 14:57:51 INFO NettyBlockTransferService: Server created on localhost:59481
21/05/03 14:57:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 14:57:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 59481, None)
21/05/03 14:57:51 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59481 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 59481, None)
21/05/03 14:57:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 59481, None)
21/05/03 14:57:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 59481, None)
21/05/03 14:57:51 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 14:57:51 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 14:57:51 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 14:57:54 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 14:57:54 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 14:57:54 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/68e4d5f6-0634-4531-9171-4b0d3b72e892
21/05/03 14:57:54 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/68e4d5f6-0634-4531-9171-4b0d3b72e892
21/05/03 14:57:54 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/68e4d5f6-0634-4531-9171-4b0d3b72e892/_tmp_space.db
21/05/03 14:57:54 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 14:57:55 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 14:57:55 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 14:57:55 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 14:57:55 INFO ObjectStore: ObjectStore, initialize called
21/05/03 14:57:55 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 14:57:55 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 14:57:56 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 14:57:57 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 14:57:57 INFO ObjectStore: Initialized ObjectStore
21/05/03 14:57:57 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 14:57:57 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 14:57:57 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 14:57:57 INFO HiveMetaStore: Added admin role in metastore
21/05/03 14:57:57 INFO HiveMetaStore: Added public role in metastore
21/05/03 14:57:57 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 14:57:57 INFO HiveMetaStore: 0: get_all_functions
21/05/03 14:57:57 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 14:57:57 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:57:57 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:57:57 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 14:57:57 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 14:57:57 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 14:57:57 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:57:57 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:57:57 INFO HiveMetaStore: 0: get_database: default
21/05/03 14:57:57 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 14:57:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 14:57:57 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 14:57:58 INFO CodeGenerator: Code generated in 165.105972 ms
21/05/03 14:57:58 INFO CodeGenerator: Code generated in 11.609413 ms
21/05/03 14:57:58 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 14:57:58 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 14:57:58 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 14:57:58 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 14:57:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 14:57:58 INFO DAGScheduler: Missing parents: List()
21/05/03 14:57:58 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 14:57:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 14:57:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 14:57:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:59481 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 14:57:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 14:57:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 14:57:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 14:57:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 14:57:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 14:57:58 INFO Executor: Fetching spark://localhost:59480/jars/sparklyr-3.0-2.12.jar with timestamp 1620068271511
21/05/03 14:57:58 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:59480 after 14 ms (0 ms spent in bootstraps)
21/05/03 14:57:58 INFO Utils: Fetching spark://localhost:59480/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-f9bf904f-32e6-41bf-b008-fdba5f3587a1/userFiles-89c75484-67fd-4996-a0f5-f2adbeb2bba8/fetchFileTemp7795654223244951926.tmp
21/05/03 14:57:58 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-f9bf904f-32e6-41bf-b008-fdba5f3587a1/userFiles-89c75484-67fd-4996-a0f5-f2adbeb2bba8/sparklyr-3.0-2.12.jar to class loader
21/05/03 14:57:59 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 14:57:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 14:57:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 14:57:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 286 ms on localhost (executor driver) (1/1)
21/05/03 14:57:59 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 14:57:59 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.457 s
21/05/03 14:57:59 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 14:57:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 14:57:59 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.500607 s
21/05/03 15:02:30 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:59481 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 15:03:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 15:03:47 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 15:03:47 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 15:03:47 INFO SecurityManager: Changing view acls groups to: 
21/05/03 15:03:47 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 15:03:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 15:03:48 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 15:03:48 INFO SparkContext: Running Spark version 3.0.1
21/05/03 15:03:48 INFO ResourceUtils: ==============================================================
21/05/03 15:03:48 INFO ResourceUtils: Resources for spark.driver:

21/05/03 15:03:48 INFO ResourceUtils: ==============================================================
21/05/03 15:03:48 INFO SparkContext: Submitted application: sparklyr
21/05/03 15:03:48 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 15:03:48 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 15:03:48 INFO SecurityManager: Changing view acls groups to: 
21/05/03 15:03:48 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 15:03:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 15:03:48 INFO Utils: Successfully started service 'sparkDriver' on port 59775.
21/05/03 15:03:49 INFO SparkEnv: Registering MapOutputTracker
21/05/03 15:03:49 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 15:03:49 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 15:03:49 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 15:03:49 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 15:03:49 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-df0b86c7-9ca3-4e91-be2a-71e368bcc327
21/05/03 15:03:49 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 15:03:49 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 15:03:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
21/05/03 15:03:49 INFO Utils: Successfully started service 'SparkUI' on port 4041.
21/05/03 15:03:49 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4041
21/05/03 15:03:49 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:59775/jars/sparklyr-3.0-2.12.jar with timestamp 1620068629430
21/05/03 15:03:49 INFO Executor: Starting executor ID driver on host localhost
21/05/03 15:03:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59777.
21/05/03 15:03:49 INFO NettyBlockTransferService: Server created on localhost:59777
21/05/03 15:03:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 15:03:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 59777, None)
21/05/03 15:03:49 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59777 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 59777, None)
21/05/03 15:03:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 59777, None)
21/05/03 15:03:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 59777, None)
21/05/03 15:03:49 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 15:03:49 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 15:03:49 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 15:03:52 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 15:03:52 INFO SparkUI: Stopped Spark web UI at http://localhost:4041
21/05/03 15:03:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 15:03:52 INFO MemoryStore: MemoryStore cleared
21/05/03 15:03:52 INFO BlockManager: BlockManager stopped
21/05/03 15:03:52 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 15:03:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 15:03:52 INFO SparkContext: Successfully stopped SparkContext
21/05/03 15:03:52 INFO ShutdownHookManager: Shutdown hook called
21/05/03 15:03:52 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-832d567f-f491-4caa-83e7-f5e3ba774fc4
21/05/03 15:03:52 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-1f807733-743c-4746-8b53-597386694fbf
21/05/03 15:03:55 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 15:03:55 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 15:03:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 15:03:55 INFO MemoryStore: MemoryStore cleared
21/05/03 15:03:55 INFO BlockManager: BlockManager stopped
21/05/03 15:03:55 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 15:03:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 15:03:55 INFO SparkContext: Successfully stopped SparkContext
21/05/03 15:03:55 INFO ShutdownHookManager: Shutdown hook called
21/05/03 15:03:55 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-a96036b0-9639-4f1c-8a37-03bd7f42c485
21/05/03 15:03:55 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-f9bf904f-32e6-41bf-b008-fdba5f3587a1
21/05/03 15:08:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 15:08:24 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 15:08:24 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 15:08:24 INFO SecurityManager: Changing view acls groups to: 
21/05/03 15:08:24 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 15:08:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 15:08:24 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 15:08:25 INFO SparkContext: Running Spark version 3.0.1
21/05/03 15:08:25 INFO ResourceUtils: ==============================================================
21/05/03 15:08:25 INFO ResourceUtils: Resources for spark.driver:

21/05/03 15:08:25 INFO ResourceUtils: ==============================================================
21/05/03 15:08:25 INFO SparkContext: Submitted application: sparklyr
21/05/03 15:08:25 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 15:08:25 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 15:08:25 INFO SecurityManager: Changing view acls groups to: 
21/05/03 15:08:25 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 15:08:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 15:08:25 INFO Utils: Successfully started service 'sparkDriver' on port 60829.
21/05/03 15:08:25 INFO SparkEnv: Registering MapOutputTracker
21/05/03 15:08:25 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 15:08:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 15:08:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 15:08:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 15:08:25 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-56608761-8fc5-4b31-a8b1-1ffd3ca5f22b
21/05/03 15:08:25 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 15:08:25 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 15:08:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 15:08:25 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 15:08:25 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/Projects/sparklyrExtensionScala/inst/java/sparklyrExtensionScala-3.0-2.12.jar at spark://localhost:60829/jars/sparklyrExtensionScala-3.0-2.12.jar with timestamp 1620068905640
21/05/03 15:08:25 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:60829/jars/sparklyr-3.0-2.12.jar with timestamp 1620068905641
21/05/03 15:08:25 INFO Executor: Starting executor ID driver on host localhost
21/05/03 15:08:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60830.
21/05/03 15:08:25 INFO NettyBlockTransferService: Server created on localhost:60830
21/05/03 15:08:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 15:08:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 60830, None)
21/05/03 15:08:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60830 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 60830, None)
21/05/03 15:08:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 60830, None)
21/05/03 15:08:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 60830, None)
21/05/03 15:08:25 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 15:08:25 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 15:08:25 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 15:08:29 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 15:08:29 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 15:08:29 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/848e167f-8c27-4b81-98cb-329507583c59
21/05/03 15:08:29 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/848e167f-8c27-4b81-98cb-329507583c59
21/05/03 15:08:29 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/848e167f-8c27-4b81-98cb-329507583c59/_tmp_space.db
21/05/03 15:08:29 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 15:08:30 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 15:08:30 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 15:08:30 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 15:08:30 INFO ObjectStore: ObjectStore, initialize called
21/05/03 15:08:30 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 15:08:30 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 15:08:31 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 15:08:32 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 15:08:32 INFO ObjectStore: Initialized ObjectStore
21/05/03 15:08:32 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 15:08:32 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 15:08:32 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 15:08:33 INFO HiveMetaStore: Added admin role in metastore
21/05/03 15:08:33 INFO HiveMetaStore: Added public role in metastore
21/05/03 15:08:33 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 15:08:33 INFO HiveMetaStore: 0: get_all_functions
21/05/03 15:08:33 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 15:08:33 INFO HiveMetaStore: 0: get_database: default
21/05/03 15:08:33 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 15:08:33 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 15:08:33 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 15:08:33 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 15:08:33 INFO HiveMetaStore: 0: get_database: default
21/05/03 15:08:33 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 15:08:33 INFO HiveMetaStore: 0: get_database: default
21/05/03 15:08:33 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 15:08:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 15:08:33 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 15:08:34 INFO CodeGenerator: Code generated in 195.324947 ms
21/05/03 15:08:34 INFO CodeGenerator: Code generated in 11.750308 ms
21/05/03 15:08:34 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 15:08:34 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 15:08:34 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 15:08:34 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 15:08:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 15:08:34 INFO DAGScheduler: Missing parents: List()
21/05/03 15:08:34 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 15:08:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 15:08:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 15:08:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:60830 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 15:08:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 15:08:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 15:08:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 15:08:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 15:08:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 15:08:34 INFO Executor: Fetching spark://localhost:60829/jars/sparklyr-3.0-2.12.jar with timestamp 1620068905641
21/05/03 15:08:34 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:60829 after 17 ms (0 ms spent in bootstraps)
21/05/03 15:08:34 INFO Utils: Fetching spark://localhost:60829/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-dc736f45-f921-49b2-b577-cf50cd5a2ea4/userFiles-f495eed4-1202-40d4-96f6-1eabf9558a5d/fetchFileTemp1980903538461752426.tmp
21/05/03 15:08:34 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-dc736f45-f921-49b2-b577-cf50cd5a2ea4/userFiles-f495eed4-1202-40d4-96f6-1eabf9558a5d/sparklyr-3.0-2.12.jar to class loader
21/05/03 15:08:34 INFO Executor: Fetching spark://localhost:60829/jars/sparklyrExtensionScala-3.0-2.12.jar with timestamp 1620068905640
21/05/03 15:08:34 INFO Utils: Fetching spark://localhost:60829/jars/sparklyrExtensionScala-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-dc736f45-f921-49b2-b577-cf50cd5a2ea4/userFiles-f495eed4-1202-40d4-96f6-1eabf9558a5d/fetchFileTemp2715784492742145929.tmp
21/05/03 15:08:34 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-dc736f45-f921-49b2-b577-cf50cd5a2ea4/userFiles-f495eed4-1202-40d4-96f6-1eabf9558a5d/sparklyrExtensionScala-3.0-2.12.jar to class loader
21/05/03 15:08:34 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 15:08:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/05/03 15:08:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 15:08:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 302 ms on localhost (executor driver) (1/1)
21/05/03 15:08:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 15:08:34 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.517 s
21/05/03 15:08:34 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 15:08:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 15:08:34 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.556996 s
21/05/03 15:08:45 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 15:08:45 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 15:08:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 15:08:45 INFO MemoryStore: MemoryStore cleared
21/05/03 15:08:45 INFO BlockManager: BlockManager stopped
21/05/03 15:08:45 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 15:08:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 15:08:45 INFO SparkContext: Successfully stopped SparkContext
21/05/03 15:08:45 INFO ShutdownHookManager: Shutdown hook called
21/05/03 15:08:45 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-dc736f45-f921-49b2-b577-cf50cd5a2ea4
21/05/03 15:08:45 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-602631dc-fddf-4f54-9a10-6804bffb8196
21/05/03 15:12:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 15:12:47 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 15:12:47 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 15:12:47 INFO SecurityManager: Changing view acls groups to: 
21/05/03 15:12:47 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 15:12:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 15:12:48 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 15:12:48 INFO SparkContext: Running Spark version 3.0.1
21/05/03 15:12:48 INFO ResourceUtils: ==============================================================
21/05/03 15:12:48 INFO ResourceUtils: Resources for spark.driver:

21/05/03 15:12:48 INFO ResourceUtils: ==============================================================
21/05/03 15:12:48 INFO SparkContext: Submitted application: sparklyr
21/05/03 15:12:48 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 15:12:48 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 15:12:48 INFO SecurityManager: Changing view acls groups to: 
21/05/03 15:12:48 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 15:12:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 15:12:48 INFO Utils: Successfully started service 'sparkDriver' on port 61952.
21/05/03 15:12:48 INFO SparkEnv: Registering MapOutputTracker
21/05/03 15:12:48 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 15:12:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 15:12:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 15:12:48 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 15:12:48 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-08e447da-a673-426c-a645-b3dd5fcb56a4
21/05/03 15:12:48 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 15:12:48 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 15:12:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 15:12:48 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 15:12:48 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/Projects/sparklyrExtensionScala/inst/java/sparklyrExtensionScala-3.0-2.12.jar at spark://localhost:61952/jars/sparklyrExtensionScala-3.0-2.12.jar with timestamp 1620069168823
21/05/03 15:12:48 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:61952/jars/sparklyr-3.0-2.12.jar with timestamp 1620069168823
21/05/03 15:12:48 INFO Executor: Starting executor ID driver on host localhost
21/05/03 15:12:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61955.
21/05/03 15:12:48 INFO NettyBlockTransferService: Server created on localhost:61955
21/05/03 15:12:48 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 15:12:48 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 61955, None)
21/05/03 15:12:48 INFO BlockManagerMasterEndpoint: Registering block manager localhost:61955 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 61955, None)
21/05/03 15:12:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 61955, None)
21/05/03 15:12:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 61955, None)
21/05/03 15:12:49 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 15:12:49 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 15:12:49 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 15:12:52 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 15:12:52 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 15:12:52 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/5e5f2bc7-0bbd-4abc-978c-7120ac5cb324
21/05/03 15:12:52 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/5e5f2bc7-0bbd-4abc-978c-7120ac5cb324
21/05/03 15:12:52 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/5e5f2bc7-0bbd-4abc-978c-7120ac5cb324/_tmp_space.db
21/05/03 15:12:52 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 15:12:53 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 15:12:53 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 15:12:53 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 15:12:53 INFO ObjectStore: ObjectStore, initialize called
21/05/03 15:12:53 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 15:12:53 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 15:12:54 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 15:12:55 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 15:12:55 INFO ObjectStore: Initialized ObjectStore
21/05/03 15:12:55 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 15:12:55 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 15:12:55 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 15:12:55 INFO HiveMetaStore: Added admin role in metastore
21/05/03 15:12:55 INFO HiveMetaStore: Added public role in metastore
21/05/03 15:12:55 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 15:12:55 INFO HiveMetaStore: 0: get_all_functions
21/05/03 15:12:55 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 15:12:55 INFO HiveMetaStore: 0: get_database: default
21/05/03 15:12:55 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 15:12:55 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 15:12:55 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 15:12:55 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 15:12:55 INFO HiveMetaStore: 0: get_database: default
21/05/03 15:12:55 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 15:12:55 INFO HiveMetaStore: 0: get_database: default
21/05/03 15:12:55 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 15:12:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 15:12:55 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 15:12:56 INFO CodeGenerator: Code generated in 194.430135 ms
21/05/03 15:12:56 INFO CodeGenerator: Code generated in 13.37877 ms
21/05/03 15:12:56 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 15:12:56 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 15:12:56 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 15:12:56 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 15:12:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 15:12:56 INFO DAGScheduler: Missing parents: List()
21/05/03 15:12:56 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 15:12:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 15:12:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 15:12:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:61955 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 15:12:57 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 15:12:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 15:12:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 15:12:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 15:12:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 15:12:57 INFO Executor: Fetching spark://localhost:61952/jars/sparklyrExtensionScala-3.0-2.12.jar with timestamp 1620069168823
21/05/03 15:12:57 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:61952 after 14 ms (0 ms spent in bootstraps)
21/05/03 15:12:57 INFO Utils: Fetching spark://localhost:61952/jars/sparklyrExtensionScala-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-e1d265b8-ac96-405f-9ef7-050fdf3fccae/userFiles-c577da33-e258-42dd-8b2f-6a5e6ecaa230/fetchFileTemp3211706490787620434.tmp
21/05/03 15:12:57 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-e1d265b8-ac96-405f-9ef7-050fdf3fccae/userFiles-c577da33-e258-42dd-8b2f-6a5e6ecaa230/sparklyrExtensionScala-3.0-2.12.jar to class loader
21/05/03 15:12:57 INFO Executor: Fetching spark://localhost:61952/jars/sparklyr-3.0-2.12.jar with timestamp 1620069168823
21/05/03 15:12:57 INFO Utils: Fetching spark://localhost:61952/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-e1d265b8-ac96-405f-9ef7-050fdf3fccae/userFiles-c577da33-e258-42dd-8b2f-6a5e6ecaa230/fetchFileTemp6165831876802025229.tmp
21/05/03 15:12:57 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-e1d265b8-ac96-405f-9ef7-050fdf3fccae/userFiles-c577da33-e258-42dd-8b2f-6a5e6ecaa230/sparklyr-3.0-2.12.jar to class loader
21/05/03 15:12:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 15:12:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 15:12:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2641 bytes result sent to driver
21/05/03 15:12:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 309 ms on localhost (executor driver) (1/1)
21/05/03 15:12:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 15:12:57 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.606 s
21/05/03 15:12:57 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 15:12:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 15:12:57 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.653146 s
21/05/03 15:19:08 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 15:19:08 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 15:19:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 15:19:08 INFO MemoryStore: MemoryStore cleared
21/05/03 15:19:08 INFO BlockManager: BlockManager stopped
21/05/03 15:19:08 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 15:19:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 15:19:08 INFO SparkContext: Successfully stopped SparkContext
21/05/03 15:19:08 INFO ShutdownHookManager: Shutdown hook called
21/05/03 15:19:08 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-e1d265b8-ac96-405f-9ef7-050fdf3fccae
21/05/03 15:19:08 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-16600f92-8806-45ed-a9b6-7a88812814a5
21/05/03 15:46:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 15:46:22 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 15:46:22 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 15:46:22 INFO SecurityManager: Changing view acls groups to: 
21/05/03 15:46:22 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 15:46:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 15:46:23 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 15:46:23 INFO SparkContext: Running Spark version 3.0.1
21/05/03 15:46:23 INFO ResourceUtils: ==============================================================
21/05/03 15:46:23 INFO ResourceUtils: Resources for spark.driver:

21/05/03 15:46:23 INFO ResourceUtils: ==============================================================
21/05/03 15:46:23 INFO SparkContext: Submitted application: sparklyr
21/05/03 15:46:23 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 15:46:23 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 15:46:23 INFO SecurityManager: Changing view acls groups to: 
21/05/03 15:46:23 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 15:46:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 15:46:23 INFO Utils: Successfully started service 'sparkDriver' on port 62943.
21/05/03 15:46:23 INFO SparkEnv: Registering MapOutputTracker
21/05/03 15:46:23 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 15:46:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 15:46:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 15:46:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 15:46:23 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-74b35438-bd0e-4d54-8aad-3a0d0f997583
21/05/03 15:46:23 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 15:46:23 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 15:46:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 15:46:24 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 15:46:24 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/Projects/sparklyrExtensionScala/inst/java/sparklyrExtensionScala-3.0-2.12.jar at spark://localhost:62943/jars/sparklyrExtensionScala-3.0-2.12.jar with timestamp 1620071184104
21/05/03 15:46:24 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:62943/jars/sparklyr-3.0-2.12.jar with timestamp 1620071184104
21/05/03 15:46:24 INFO Executor: Starting executor ID driver on host localhost
21/05/03 15:46:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62944.
21/05/03 15:46:24 INFO NettyBlockTransferService: Server created on localhost:62944
21/05/03 15:46:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 15:46:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 62944, None)
21/05/03 15:46:24 INFO BlockManagerMasterEndpoint: Registering block manager localhost:62944 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 62944, None)
21/05/03 15:46:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 62944, None)
21/05/03 15:46:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 62944, None)
21/05/03 15:46:24 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 15:46:24 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 15:46:24 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 15:46:26 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 15:46:26 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 15:46:27 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/999cd1c3-8468-46de-95c4-f19e5b51fdfe
21/05/03 15:46:27 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/999cd1c3-8468-46de-95c4-f19e5b51fdfe
21/05/03 15:46:27 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/999cd1c3-8468-46de-95c4-f19e5b51fdfe/_tmp_space.db
21/05/03 15:46:27 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 15:46:27 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 15:46:27 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 15:46:27 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 15:46:27 INFO ObjectStore: ObjectStore, initialize called
21/05/03 15:46:27 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 15:46:27 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 15:46:28 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 15:46:29 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 15:46:29 INFO ObjectStore: Initialized ObjectStore
21/05/03 15:46:29 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 15:46:29 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 15:46:29 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 15:46:29 INFO HiveMetaStore: Added admin role in metastore
21/05/03 15:46:29 INFO HiveMetaStore: Added public role in metastore
21/05/03 15:46:29 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 15:46:30 INFO HiveMetaStore: 0: get_all_functions
21/05/03 15:46:30 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 15:46:30 INFO HiveMetaStore: 0: get_database: default
21/05/03 15:46:30 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 15:46:30 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 15:46:30 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 15:46:30 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 15:46:30 INFO HiveMetaStore: 0: get_database: default
21/05/03 15:46:30 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 15:46:30 INFO HiveMetaStore: 0: get_database: default
21/05/03 15:46:30 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 15:46:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 15:46:30 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 15:46:30 INFO CodeGenerator: Code generated in 163.031264 ms
21/05/03 15:46:30 INFO CodeGenerator: Code generated in 10.185386 ms
21/05/03 15:46:31 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 15:46:31 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 15:46:31 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 15:46:31 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 15:46:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 15:46:31 INFO DAGScheduler: Missing parents: List()
21/05/03 15:46:31 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 15:46:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 15:46:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 15:46:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:62944 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 15:46:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 15:46:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 15:46:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 15:46:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 15:46:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 15:46:31 INFO Executor: Fetching spark://localhost:62943/jars/sparklyrExtensionScala-3.0-2.12.jar with timestamp 1620071184104
21/05/03 15:46:31 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:62943 after 13 ms (0 ms spent in bootstraps)
21/05/03 15:46:31 INFO Utils: Fetching spark://localhost:62943/jars/sparklyrExtensionScala-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-239c2bc7-c3e3-46b5-ace8-337a3697a90c/userFiles-d3f09304-e674-4ebf-8267-017858936f86/fetchFileTemp3438287945862135493.tmp
21/05/03 15:46:31 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-239c2bc7-c3e3-46b5-ace8-337a3697a90c/userFiles-d3f09304-e674-4ebf-8267-017858936f86/sparklyrExtensionScala-3.0-2.12.jar to class loader
21/05/03 15:46:31 INFO Executor: Fetching spark://localhost:62943/jars/sparklyr-3.0-2.12.jar with timestamp 1620071184104
21/05/03 15:46:31 INFO Utils: Fetching spark://localhost:62943/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-239c2bc7-c3e3-46b5-ace8-337a3697a90c/userFiles-d3f09304-e674-4ebf-8267-017858936f86/fetchFileTemp7982073794483324696.tmp
21/05/03 15:46:31 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-239c2bc7-c3e3-46b5-ace8-337a3697a90c/userFiles-d3f09304-e674-4ebf-8267-017858936f86/sparklyr-3.0-2.12.jar to class loader
21/05/03 15:46:31 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 15:46:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/05/03 15:46:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2684 bytes result sent to driver
21/05/03 15:46:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 299 ms on localhost (executor driver) (1/1)
21/05/03 15:46:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 15:46:31 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.580 s
21/05/03 15:46:31 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 15:46:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 15:46:31 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.622324 s
21/05/03 16:02:14 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 16:02:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 16:02:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 16:02:14 INFO MemoryStore: MemoryStore cleared
21/05/03 16:02:14 INFO BlockManager: BlockManager stopped
21/05/03 16:02:14 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 16:02:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 16:02:14 INFO SparkContext: Successfully stopped SparkContext
21/05/03 16:02:14 INFO ShutdownHookManager: Shutdown hook called
21/05/03 16:02:14 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-62814b62-8a19-442c-b0b0-e9e54828caf2
21/05/03 16:02:14 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-239c2bc7-c3e3-46b5-ace8-337a3697a90c
21/05/03 16:27:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 16:27:54 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 16:27:54 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 16:27:54 INFO SecurityManager: Changing view acls groups to: 
21/05/03 16:27:54 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 16:27:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 16:27:55 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 16:27:55 INFO SparkContext: Running Spark version 3.0.1
21/05/03 16:27:55 INFO ResourceUtils: ==============================================================
21/05/03 16:27:55 INFO ResourceUtils: Resources for spark.driver:

21/05/03 16:27:55 INFO ResourceUtils: ==============================================================
21/05/03 16:27:55 INFO SparkContext: Submitted application: sparklyr
21/05/03 16:27:55 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 16:27:55 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 16:27:55 INFO SecurityManager: Changing view acls groups to: 
21/05/03 16:27:55 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 16:27:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 16:27:55 INFO Utils: Successfully started service 'sparkDriver' on port 64640.
21/05/03 16:27:55 INFO SparkEnv: Registering MapOutputTracker
21/05/03 16:27:55 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 16:27:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 16:27:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 16:27:55 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 16:27:55 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-b2e69afe-93aa-4227-86e5-92bb1a566031
21/05/03 16:27:55 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 16:27:55 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 16:27:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 16:27:56 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 16:27:56 INFO SparkContext: Added JAR file:///Users/katherinegoznikar/Projects/sparklyrExtensionScala/inst/java/sparklyrExtensionScala-3.0-2.12.jar at spark://localhost:64640/jars/sparklyrExtensionScala-3.0-2.12.jar with timestamp 1620073676071
21/05/03 16:27:56 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:64640/jars/sparklyr-3.0-2.12.jar with timestamp 1620073676072
21/05/03 16:27:56 INFO Executor: Starting executor ID driver on host localhost
21/05/03 16:27:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64641.
21/05/03 16:27:56 INFO NettyBlockTransferService: Server created on localhost:64641
21/05/03 16:27:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 16:27:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 64641, None)
21/05/03 16:27:56 INFO BlockManagerMasterEndpoint: Registering block manager localhost:64641 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 64641, None)
21/05/03 16:27:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 64641, None)
21/05/03 16:27:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 64641, None)
21/05/03 16:27:56 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 16:27:56 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 16:27:56 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 16:27:58 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 16:27:58 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 16:27:58 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/028b696a-a519-4726-b805-6e4340121143
21/05/03 16:27:58 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/028b696a-a519-4726-b805-6e4340121143
21/05/03 16:27:58 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/028b696a-a519-4726-b805-6e4340121143/_tmp_space.db
21/05/03 16:27:58 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 16:27:59 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 16:27:59 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 16:27:59 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 16:27:59 INFO ObjectStore: ObjectStore, initialize called
21/05/03 16:27:59 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 16:27:59 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 16:28:00 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 16:28:01 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 16:28:01 INFO ObjectStore: Initialized ObjectStore
21/05/03 16:28:01 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 16:28:01 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 16:28:01 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 16:28:01 INFO HiveMetaStore: Added admin role in metastore
21/05/03 16:28:01 INFO HiveMetaStore: Added public role in metastore
21/05/03 16:28:01 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 16:28:02 INFO HiveMetaStore: 0: get_all_functions
21/05/03 16:28:02 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 16:28:02 INFO HiveMetaStore: 0: get_database: default
21/05/03 16:28:02 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 16:28:02 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 16:28:02 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 16:28:02 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 16:28:02 INFO HiveMetaStore: 0: get_database: default
21/05/03 16:28:02 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 16:28:02 INFO HiveMetaStore: 0: get_database: default
21/05/03 16:28:02 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 16:28:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 16:28:02 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 16:28:02 INFO CodeGenerator: Code generated in 177.718444 ms
21/05/03 16:28:02 INFO CodeGenerator: Code generated in 10.506764 ms
21/05/03 16:28:03 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 16:28:03 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 16:28:03 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 16:28:03 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 16:28:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 16:28:03 INFO DAGScheduler: Missing parents: List()
21/05/03 16:28:03 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 16:28:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 16:28:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 16:28:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:64641 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 16:28:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 16:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 16:28:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 16:28:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 16:28:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 16:28:03 INFO Executor: Fetching spark://localhost:64640/jars/sparklyr-3.0-2.12.jar with timestamp 1620073676072
21/05/03 16:28:03 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:64640 after 15 ms (0 ms spent in bootstraps)
21/05/03 16:28:03 INFO Utils: Fetching spark://localhost:64640/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-8a58937c-795a-4226-b604-ea63351ba735/userFiles-f07a5071-2f96-4cbb-84f4-28bae8028a56/fetchFileTemp5083761610405766350.tmp
21/05/03 16:28:03 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-8a58937c-795a-4226-b604-ea63351ba735/userFiles-f07a5071-2f96-4cbb-84f4-28bae8028a56/sparklyr-3.0-2.12.jar to class loader
21/05/03 16:28:03 INFO Executor: Fetching spark://localhost:64640/jars/sparklyrExtensionScala-3.0-2.12.jar with timestamp 1620073676071
21/05/03 16:28:03 INFO Utils: Fetching spark://localhost:64640/jars/sparklyrExtensionScala-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-8a58937c-795a-4226-b604-ea63351ba735/userFiles-f07a5071-2f96-4cbb-84f4-28bae8028a56/fetchFileTemp5050984560122419409.tmp
21/05/03 16:28:03 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-8a58937c-795a-4226-b604-ea63351ba735/userFiles-f07a5071-2f96-4cbb-84f4-28bae8028a56/sparklyrExtensionScala-3.0-2.12.jar to class loader
21/05/03 16:28:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 16:28:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
21/05/03 16:28:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2684 bytes result sent to driver
21/05/03 16:28:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 318 ms on localhost (executor driver) (1/1)
21/05/03 16:28:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 16:28:03 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.579 s
21/05/03 16:28:03 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 16:28:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 16:28:03 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.623817 s
21/05/03 16:28:03 INFO HiveMetaStore: 0: get_database: default
21/05/03 16:28:03 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 16:28:03 INFO HiveMetaStore: 0: get_database: default
21/05/03 16:28:03 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 16:28:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 16:28:03 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 16:28:03 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 16:28:03 INFO DAGScheduler: Registering RDD 8 (count at utils.scala:135) as input to shuffle 1
21/05/03 16:28:03 INFO DAGScheduler: Got job 1 (count at utils.scala:135) with 1 output partitions
21/05/03 16:28:03 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/05/03 16:28:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/05/03 16:28:03 INFO DAGScheduler: Missing parents: List()
21/05/03 16:28:03 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/05/03 16:28:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 16:28:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 16:28:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:64641 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 16:28:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/05/03 16:28:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 16:28:03 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/05/03 16:28:03 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 16:28:03 INFO Executor: Running task 0.0 in stage 3.0 (TID 1)
21/05/03 16:28:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 16:28:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/03 16:28:03 INFO Executor: Finished task 0.0 in stage 3.0 (TID 1). 2641 bytes result sent to driver
21/05/03 16:28:03 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 1) in 6 ms on localhost (executor driver) (1/1)
21/05/03 16:28:03 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/03 16:28:03 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.013 s
21/05/03 16:28:03 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 16:28:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/05/03 16:28:03 INFO DAGScheduler: Job 1 finished: count at utils.scala:135, took 0.016357 s
21/05/03 16:31:31 INFO SparkContext: Invoking stop() from shutdown hook
21/05/03 16:31:31 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/05/03 16:31:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/03 16:31:31 INFO MemoryStore: MemoryStore cleared
21/05/03 16:31:31 INFO BlockManager: BlockManager stopped
21/05/03 16:31:31 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/03 16:31:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/03 16:31:31 INFO SparkContext: Successfully stopped SparkContext
21/05/03 16:31:31 INFO ShutdownHookManager: Shutdown hook called
21/05/03 16:31:31 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-8a58937c-795a-4226-b604-ea63351ba735
21/05/03 16:31:31 INFO ShutdownHookManager: Deleting directory /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-e12ccb9e-a7ce-4e1d-b6f1-4cce757c901c
21/05/03 16:36:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/03 16:36:20 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 16:36:20 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 16:36:20 INFO SecurityManager: Changing view acls groups to: 
21/05/03 16:36:20 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 16:36:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 16:36:21 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 16:36:21 INFO SparkContext: Running Spark version 3.0.1
21/05/03 16:36:21 INFO ResourceUtils: ==============================================================
21/05/03 16:36:21 INFO ResourceUtils: Resources for spark.driver:

21/05/03 16:36:21 INFO ResourceUtils: ==============================================================
21/05/03 16:36:21 INFO SparkContext: Submitted application: sparklyr
21/05/03 16:36:21 INFO SecurityManager: Changing view acls to: katherinegoznikar
21/05/03 16:36:21 INFO SecurityManager: Changing modify acls to: katherinegoznikar
21/05/03 16:36:21 INFO SecurityManager: Changing view acls groups to: 
21/05/03 16:36:21 INFO SecurityManager: Changing modify acls groups to: 
21/05/03 16:36:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(katherinegoznikar); groups with view permissions: Set(); users  with modify permissions: Set(katherinegoznikar); groups with modify permissions: Set()
21/05/03 16:36:21 INFO Utils: Successfully started service 'sparkDriver' on port 64872.
21/05/03 16:36:21 INFO SparkEnv: Registering MapOutputTracker
21/05/03 16:36:21 INFO SparkEnv: Registering BlockManagerMaster
21/05/03 16:36:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/03 16:36:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/03 16:36:21 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/03 16:36:21 INFO DiskBlockManager: Created local directory at /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/blockmgr-7b5c71e7-b52c-444c-b99b-434851ec53e1
21/05/03 16:36:21 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/05/03 16:36:21 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/03 16:36:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/03 16:36:21 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/05/03 16:36:21 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/4.0/Resources/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:64872/jars/sparklyr-3.0-2.12.jar with timestamp 1620074181710
21/05/03 16:36:21 INFO Executor: Starting executor ID driver on host localhost
21/05/03 16:36:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64873.
21/05/03 16:36:21 INFO NettyBlockTransferService: Server created on localhost:64873
21/05/03 16:36:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/03 16:36:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 64873, None)
21/05/03 16:36:21 INFO BlockManagerMasterEndpoint: Registering block manager localhost:64873 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 64873, None)
21/05/03 16:36:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 64873, None)
21/05/03 16:36:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 64873, None)
21/05/03 16:36:22 INFO SharedState: loading hive config file: file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 16:36:22 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse').
21/05/03 16:36:22 INFO SharedState: Warehouse path is 'file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse'.
21/05/03 16:36:24 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/05/03 16:36:24 INFO HiveConf: Found configuration file file:/Users/katherinegoznikar/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/05/03 16:36:24 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/99fd568d-44b9-4521-a101-f698cc91ed86
21/05/03 16:36:24 INFO SessionState: Created local directory: /var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/katherinegoznikar/99fd568d-44b9-4521-a101-f698cc91ed86
21/05/03 16:36:24 INFO SessionState: Created HDFS directory: /tmp/hive/katherinegoznikar/99fd568d-44b9-4521-a101-f698cc91ed86/_tmp_space.db
21/05/03 16:36:24 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/Users/katherinegoznikar/Projects/sparklyrExtensionScala/spark-warehouse
21/05/03 16:36:25 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/05/03 16:36:25 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/05/03 16:36:25 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/05/03 16:36:25 INFO ObjectStore: ObjectStore, initialize called
21/05/03 16:36:25 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/05/03 16:36:25 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/05/03 16:36:26 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/05/03 16:36:27 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/05/03 16:36:27 INFO ObjectStore: Initialized ObjectStore
21/05/03 16:36:27 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/05/03 16:36:27 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore katherinegoznikar@127.0.0.1
21/05/03 16:36:27 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/05/03 16:36:27 INFO HiveMetaStore: Added admin role in metastore
21/05/03 16:36:27 INFO HiveMetaStore: Added public role in metastore
21/05/03 16:36:27 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/05/03 16:36:27 INFO HiveMetaStore: 0: get_all_functions
21/05/03 16:36:27 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_all_functions	
21/05/03 16:36:27 INFO HiveMetaStore: 0: get_database: default
21/05/03 16:36:27 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 16:36:27 INFO HiveMetaStore: 0: get_database: global_temp
21/05/03 16:36:27 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/05/03 16:36:27 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/05/03 16:36:27 INFO HiveMetaStore: 0: get_database: default
21/05/03 16:36:27 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 16:36:27 INFO HiveMetaStore: 0: get_database: default
21/05/03 16:36:27 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_database: default	
21/05/03 16:36:27 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/05/03 16:36:27 INFO audit: ugi=katherinegoznikar	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/05/03 16:36:28 INFO CodeGenerator: Code generated in 176.92552 ms
21/05/03 16:36:28 INFO CodeGenerator: Code generated in 11.178386 ms
21/05/03 16:36:28 INFO SparkContext: Starting job: count at utils.scala:135
21/05/03 16:36:28 INFO DAGScheduler: Registering RDD 2 (count at utils.scala:135) as input to shuffle 0
21/05/03 16:36:28 INFO DAGScheduler: Got job 0 (count at utils.scala:135) with 1 output partitions
21/05/03 16:36:28 INFO DAGScheduler: Final stage: ResultStage 1 (count at utils.scala:135)
21/05/03 16:36:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/03 16:36:28 INFO DAGScheduler: Missing parents: List()
21/05/03 16:36:28 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135), which has no missing parents
21/05/03 16:36:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/05/03 16:36:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/05/03 16:36:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:64873 (size: 5.0 KiB, free: 912.3 MiB)
21/05/03 16:36:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/05/03 16:36:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/05/03 16:36:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/05/03 16:36:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7325 bytes)
21/05/03 16:36:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 0)
21/05/03 16:36:29 INFO Executor: Fetching spark://localhost:64872/jars/sparklyr-3.0-2.12.jar with timestamp 1620074181710
21/05/03 16:36:29 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:64872 after 28 ms (0 ms spent in bootstraps)
21/05/03 16:36:29 INFO Utils: Fetching spark://localhost:64872/jars/sparklyr-3.0-2.12.jar to /private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-3851eaf7-e7a7-484b-b53c-9d734ba96374/userFiles-67b8286c-83d7-4966-be20-1867e030e16d/fetchFileTemp8337142649689200040.tmp
21/05/03 16:36:29 INFO Executor: Adding file:/private/var/folders/cs/8wl45cxd3cs8vgnbpxbvw80r0000gn/T/spark-3851eaf7-e7a7-484b-b53c-9d734ba96374/userFiles-67b8286c-83d7-4966-be20-1867e030e16d/sparklyr-3.0-2.12.jar to class loader
21/05/03 16:36:29 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/03 16:36:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/05/03 16:36:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 0). 2684 bytes result sent to driver
21/05/03 16:36:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 0) in 320 ms on localhost (executor driver) (1/1)
21/05/03 16:36:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/03 16:36:29 INFO DAGScheduler: ResultStage 1 (count at utils.scala:135) finished in 0.593 s
21/05/03 16:36:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/03 16:36:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/03 16:36:29 INFO DAGScheduler: Job 0 finished: count at utils.scala:135, took 0.634201 s
